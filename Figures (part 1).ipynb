{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8868ed26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import slideflow as sf\n",
    "import multiprocessing as mp\n",
    "from slideflow.model import build_feature_extractor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from slideflow.gan.stylegan3.stylegan3 import dnnlib, legacy, utils\n",
    "import torch\n",
    "from e4e3.utils import common, train_utils\n",
    "from e4e3.utils.model_utils import setup_model\n",
    "import torchvision.transforms.functional as F_transform\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f8a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Project working directory\n",
    "PROJECT_DIR = os.getcwd()\n",
    "device = torch.device('cuda:3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dc28ee",
   "metadata": {},
   "source": [
    "# Generate Samples Images with HistoXGAN and Alternative Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d43925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we must load all the encoders into memory\n",
    "\n",
    "#Set Backbone to 'RETCCL' to generate iamges with RETCCL based encoders\n",
    "backbone = \"CTP\"\n",
    "\n",
    "available_gpus = [torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
    "device = torch.device('cuda:3')\n",
    "\n",
    "\n",
    "if backbone == \"CTP\":\n",
    "    feature_extractor = build_feature_extractor('ctranspath', tile_px=512, device = device)\n",
    "else:\n",
    "    feature_extractor = build_feature_extractor('retccl', tile_px=512, device = device)\n",
    "\n",
    "\n",
    "\n",
    "netctp_simple, opts = setup_model(PROJECT_DIR + \"/experiment/simple_\" + backbone + \"/checkpoints/iteration_200000.pt\", \"SingleStyleCodeEncoder\", device)\n",
    "netctp_e4e, opts = setup_model(PROJECT_DIR + \"/experiment/e4e_\" + backbone + \"/checkpoints/iteration_200000.pt\", \"Encoder4Editing\", device)\n",
    "if backbone == \"CTP\":\n",
    "    netld, opts = setup_model(PROJECT_DIR + \"/experiment/lpips_dists/checkpoints/iteration_200000.pt\", \"Encoder4Editing\", device)\n",
    "else:\n",
    "    netld, opts = setup_model(PROJECT_DIR + \"/experiment/lpips_dists_discrim/checkpoints/iteration_200000.pt\", \"Encoder4Editing\", device)\n",
    "\n",
    "net_models = [netld, netctp_simple, netctp_e4e]\n",
    "\n",
    "\n",
    "def forward(batch, net, device):\n",
    "    x = batch[0] \n",
    "    y = batch[0]\n",
    "    x = F_transform.resize(x, 256)\n",
    "    x, y = x.to(device).float(), y.to(device).float()\n",
    "    y_hat, latent = net.forward(x, return_latents=True)\n",
    "    return x, y, y_hat, latent\n",
    "\n",
    "G = None\n",
    "if backbone == \"RETCCL\":\n",
    "    with dnnlib.util.open_url(PROJECT_DIR + '/FINAL_MODELS/RetCCL/snapshot.pkl') as f:\n",
    "        G = legacy.load_network_pkl(f)['G_ema'].to(device)\n",
    "else:\n",
    "    with dnnlib.util.open_url(PROJECT_DIR + '/FINAL_MODELS/CTransPath/snapshot.pkl') as f:\n",
    "        G = legacy.load_network_pkl(f)['G_ema'].to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6335d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note - to use the alternative encoders tested in this study, the 'real' image needs to be provided, not just image features\n",
    "#IF CPTAC slides are available and TFRecords are extracted, please update the /PROJECTS/HistoXGAN/datasets.json file to\n",
    "#indicate the location of TFRecords for the CPTAC datasets\n",
    "\n",
    "#Alternatively, leave the following variables as True - this will load input images that were used in the publication figures\n",
    "#and generate the corresponding 'generated' images from the alternative encoders and HistoXGAN\n",
    "USE_SAVED_INPUT_IMAGES = True\n",
    "\n",
    "\n",
    "imgs_dict = {}\n",
    "imgs_final = {}\n",
    "\n",
    "source_list_CPTAC =  [\"CPTAC_HNSC\", \"CPTAC_LUAD\", \"CPTAC_LSCC\", \"CPTAC_BRCA\", \"CPTAC_COADREAD_NO_ROI\", \"CPTAC_GBM_NO_ROI\", \"CPTAC_PDA_NO_ROI\", \"CPTAC_UCEC_NO_ROI\"]\n",
    "\n",
    "if not USE_SAVED_INPUT_IMAGES:\n",
    "    P = sf.Project(PROJECT_DIR + '/PROJECTS/HistoXGAN/')\n",
    "\n",
    "    #Must ensure the datasets are properly set up\n",
    "    \n",
    "    P.annotations = PROJECT_DIR + 'PROJECTS/HistoXGAN/cptac_all_annotations.csv'\n",
    "\n",
    "    for s in source_list_CPTAC:\n",
    "        P.sources = [s]\n",
    "        imgs = []\n",
    "        dataset = P.dataset(tile_px=512, tile_um=400)\n",
    "        df_train = dataset.torch(batch_size=1, num_workers=8, infinite = False)\n",
    "        with torch.no_grad():\n",
    "            batch_count = 0\n",
    "            for batch_idx, batch in enumerate(df_train):\n",
    "                for i in range(1):\n",
    "                    img_col = []\n",
    "                    for net in net_models:\n",
    "                        x, y, y_hat, latent = forward(batch, net, device)\n",
    "                        y = common.tensor2im(y[i])\n",
    "                        y_hat = common.tensor2im(y_hat[i])\n",
    "                        if len(img_col) == 0:\n",
    "                            img_col += [y]\n",
    "                        img_col += [y_hat]\n",
    "                    img_col += [((G(feature_extractor((batch[0].to(device)+1)*127.5), 0, noise_mode ='const') + 1)*127.5).permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[i].cpu().numpy()]\n",
    "                    imgs += [img_col]\n",
    "                imgs_dict[s] = imgs\n",
    "                break\n",
    "        imgs_final[s] = imgs_dict[s][0]\n",
    "else:\n",
    "    import pickle\n",
    "    #Loading the 'source' image from saved images for publication\n",
    "    if backbone == 'RETCCL':\n",
    "        with open(PROJECT_DIR + '/FINAL_IMAGES/img_display_cptac_retccl.pkl', 'rb') as f:\n",
    "            imgs_input = pickle.load(f)\n",
    "    else:\n",
    "        with open(PROJECT_DIR + '/FINAL_IMAGES/img_display_cptac.pkl', 'rb') as f:\n",
    "            imgs_final = pickle.load(f)\n",
    "    for s in source_list_CPTAC:\n",
    "        imgs = []\n",
    "        with torch.no_grad():\n",
    "            batch_count = 0\n",
    "            batch = torch.tensor(np.array(imgs_input[s][0])/127.5 - 1, dtype = torch.float).permute(2,0,1).unsqueeze(dim = 0).unsqueeze(dim = 0).to(device)\n",
    "            for i in range(1):\n",
    "                img_col = []\n",
    "                for net in net_models:\n",
    "                    x, y, y_hat, latent = forward(batch, net, device)\n",
    "                    y = common.tensor2im(y[i])\n",
    "                    y_hat = common.tensor2im(y_hat[i])\n",
    "                    if len(img_col) == 0:\n",
    "                        img_col += [y]\n",
    "                    img_col += [y_hat]\n",
    "                img_col += [((G(feature_extractor((batch[0].to(device)+1)*127.5), 0, noise_mode ='const') + 1)*127.5).permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[i].cpu().numpy()]\n",
    "                imgs += [img_col]\n",
    "            imgs_dict[s] = imgs\n",
    "        imgs_final[s] = imgs_dict[s][0]\n",
    "\n",
    "        \n",
    "#Code to display the generated images\n",
    "imgs = []\n",
    "for img in imgs_final:\n",
    "    imgs += [imgs_final[img]]\n",
    "fig, axs2 = plt.subplots(len(imgs[0]), len(imgs)) #, dpi = 300, figsize = (10, 10/8*5))#(2*len(imgs), 2*len(imgs[0])))\n",
    "col = 0\n",
    "for img_name in imgs_final:\n",
    "    img_col = imgs_final[img_name]\n",
    "    row = 0\n",
    "    for img in img_col:\n",
    "        axs2[row][col].imshow(img)\n",
    "        axs2[row][col].set_xticks([])\n",
    "        axs2[row][col].set_yticks([])\n",
    "        axs2[row][col].xaxis.set_label_position('top')\n",
    "        axs2[row][col].set_aspect('auto')\n",
    "        row = row + 1\n",
    "        \n",
    "    str_name = img_name[6:]\n",
    "    str_name = str_name.replace(\"_NO_ROI\", \"\")\n",
    "    str_name = str_name.replace(\"COADREAD\", \"COAD\")\n",
    "    axs2[0][col].set_xlabel(str_name)\n",
    "    col = col + 1\n",
    "fig.subplots_adjust(left = 0, top = 1, right = 1, bottom = 0, wspace=-0.1, hspace=0)\n",
    "axs2[0][0].set_ylabel(\"Original\")\n",
    "axs2[1][0].set_ylabel(\"LPIPS / DISTS\")\n",
    "axs2[2][0].set_ylabel(\"SingleStyle\")\n",
    "axs2[3][0].set_ylabel(\"Encoder4Editing\")\n",
    "axs2[4][0].set_ylabel(\"HistoXGAN\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19841a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO SAVE GENERATED IMAGES FOR USE IN THE FOLLOWING COMPOSITE FIGURES FOR PUBLICATION\n",
    "\n",
    "if backbone == \"CTP\":\n",
    "    f = open(PROJECT_DIR + '/FINAL_IMAGES/img_display_cptac.pkl', 'wb')\n",
    "    pickle.dump(imgs_final, f)\n",
    "    f.close()\n",
    "else:\n",
    "    f = open(PROJECT_DIR + '/FINAL_IMAGES/img_display_cptac_retccl.pkl', 'wb')\n",
    "    pickle.dump(imgs_final, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da4ae2",
   "metadata": {},
   "source": [
    "# Figure 2, Supplemental Figure 2, and Supplemental Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6417f6",
   "metadata": {},
   "source": [
    "## These figures include samples of generated images for the different encoders, as well as the aveage error in reconstruction across datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b90a30",
   "metadata": {},
   "source": [
    "### Supplemental Tables 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c22c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to set prefix for which data to load\n",
    "prefix = 'RETCCL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8de18f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1\n",
    "\n",
    "df1 = pd.read_csv(PROJECT_DIR + \"/MERGEDLOSS/\" + prefix + \"LPIPSDISTS.csv\", index_col = 0)\n",
    "df2 = pd.read_csv(PROJECT_DIR + \"/MERGEDLOSS/SIMPLE\" + prefix + \".csv\", index_col = 0)\n",
    "df3 = pd.read_csv(PROJECT_DIR + \"/MERGEDLOSS/E4E\" + prefix + \".csv\", index_col = 0)\n",
    "df4 = pd.read_csv(PROJECT_DIR + \"/MERGEDLOSS/\" + prefix + \"GAN.csv\", index_col = 0)\n",
    "df1_tcga = df1[df1.index.str.contains(\"TCGA\")]\n",
    "df1_cptac= df1[df1.index.str.contains(\"CPTAC\")]\n",
    "df2_tcga = df2[df2.index.str.contains(\"TCGA\")]\n",
    "df2_cptac = df2[df2.index.str.contains(\"CPTAC\")]\n",
    "df3_tcga = df3[df3.index.str.contains(\"TCGA\")]\n",
    "df3_cptac = df3[df3.index.str.contains(\"CPTAC\")]\n",
    "df4_tcga = df4[df4.index.str.contains(\"TCGA\")]\n",
    "df4_cptac = df4[df4.index.str.contains(\"CPTAC\")]\n",
    "df1['Source'] = df1.index.str[0:5].str.replace(\"_\", \"\")\n",
    "df1['Subset'] = df1.index.str[5:].str.replace(\"_\", \"\")\n",
    "df1['n'] = df1['count']\n",
    "df1['LPIP / DISTS'] = df1['mean'].map(lambda x: '{:.3f}'.format(x)) + \" (\" + df1['stdev'].map(lambda x: '{:.3f}'.format(x)) + \") \"\n",
    "df1['Single Layer'] = df2['mean'].map(lambda x: '{:.3f}'.format(x)) + \" (\" + df2['stdev'].map(lambda x: '{:.3f}'.format(x)) + \") \"\n",
    "df1['Encoder4Editing'] = df3['mean'].map(lambda x: '{:.3f}'.format(x)) + \" (\" + df3['stdev'].map(lambda x: '{:.3f}'.format(x)) + \") \"\n",
    "df1['LatentGAN'] = df4['mean'].map(lambda x: '{:.3f}'.format(x)) + \" (\" + df4['stdev'].map(lambda x: '{:.3f}'.format(x)) + \") \"\n",
    "df1['L_raw_mean'] = df1['mean'] * df1['n']\n",
    "df1['S_raw_mean'] = df2['mean'] * df1['n']\n",
    "df1['E_raw_mean'] = df3['mean'] * df1['n']\n",
    "df1['H_raw_mean'] = df4['mean'] * df1['n']\n",
    "\n",
    "# print(\"Overall TCGA Means\")\n",
    "# print(df1.loc[df1.Source == 'TCGA', 'L_raw_mean'].sum() / df1.loc[df1.Source == 'TCGA', 'n'].sum())\n",
    "# print(df1.loc[df1.Source == 'TCGA', 'S_raw_mean'].sum() / df1.loc[df1.Source == 'TCGA', 'n'].sum())\n",
    "# print(df1.loc[df1.Source == 'TCGA', 'E_raw_mean'].sum() / df1.loc[df1.Source == 'TCGA', 'n'].sum())\n",
    "# print(df1.loc[df1.Source == 'TCGA', 'H_raw_mean'].sum() / df1.loc[df1.Source == 'TCGA', 'n'].sum())\n",
    "\n",
    "# print(\"Overall CPTAC Means\")\n",
    "# print(df1.loc[df1.Source == 'CPTAC', 'L_raw_mean'].sum() / df1.loc[df1.Source == 'CPTAC', 'n'].sum())\n",
    "# print(df1.loc[df1.Source == 'CPTAC', 'S_raw_mean'].sum() / df1.loc[df1.Source == 'CPTAC', 'n'].sum())\n",
    "# print(df1.loc[df1.Source == 'CPTAC', 'E_raw_mean'].sum() / df1.loc[df1.Source == 'CPTAC', 'n'].sum())\n",
    "# print(df1.loc[df1.Source == 'CPTAC', 'H_raw_mean'].sum() / df1.loc[df1.Source == 'CPTAC', 'n'].sum())\n",
    "\n",
    "df1.loc[df1.Source == 'TCGA']\n",
    "df1 = df1.drop(['count', 'mean', 'stdev', 'stderr'], axis = 1)\n",
    "\n",
    "df1.sort_values(by = ['Source', 'Subset'], ascending = [False, True], inplace=True)\n",
    "\n",
    "print(df1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8239bfb2",
   "metadata": {},
   "source": [
    "### FIGURE 2 - CTransPath Examples and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d96e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to set prefix for which data to load\n",
    "prefix = 'CTP'\n",
    "%matplotlib inline\n",
    "\n",
    "df1 = pd.read_csv(PROJECT_DIR + \"/MERGEDLOSS/\" + prefix + \"LPIPSDISTS.csv\", index_col = 0)\n",
    "df2 = pd.read_csv(PROJECT_DIR + \"/MERGEDLOSS/SIMPLE\" + prefix + \".csv\", index_col = 0)\n",
    "df3 = pd.read_csv(PROJECT_DIR + \"/MERGEDLOSS/E4E\" + prefix + \".csv\", index_col = 0)\n",
    "df4 = pd.read_csv(PROJECT_DIR + \"/MERGEDLOSS/\" + prefix + \"GAN.csv\", index_col = 0)\n",
    "df1_tcga = df1[df1.index.str.contains(\"TCGA\")]\n",
    "df1_cptac= df1[df1.index.str.contains(\"CPTAC\")]\n",
    "df2_tcga = df2[df2.index.str.contains(\"TCGA\")]\n",
    "df2_cptac = df2[df2.index.str.contains(\"CPTAC\")]\n",
    "df3_tcga = df3[df3.index.str.contains(\"TCGA\")]\n",
    "df3_cptac = df3[df3.index.str.contains(\"CPTAC\")]\n",
    "df4_tcga = df4[df4.index.str.contains(\"TCGA\")]\n",
    "df4_cptac = df4[df4.index.str.contains(\"CPTAC\")]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 12), dpi = 300)\n",
    "\n",
    "subfigs = fig.subfigures(2, 1)\n",
    "\n",
    "axs = subfigs[0].subplots(1, 2, sharey = True,  gridspec_kw= {'width_ratios': [3.2, 1]})\n",
    "\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "\n",
    "def bar_plot(ax, df, dataset):\n",
    "\n",
    "    ic = 6\n",
    "    if dataset == 'TCGA':\n",
    "        ic = 5\n",
    "    tick_labels = df[0].index.str[ic:].values\n",
    "    tick_labels.sort()\n",
    "    tick_labels = tick_labels\n",
    "    tick_counts = [list(range(len(df[0].index.values))), [], [], []]\n",
    "    tick_counts[0] = [x for x in tick_counts[0]]\n",
    "    for df2_n in df[1].index.str[ic:].values:\n",
    "        tick_counts[1] += [list(tick_labels).index(df2_n)]\n",
    "    for df3_n in df[2].index.str[ic:].values:\n",
    "        tick_counts[2] += [list(tick_labels).index(df3_n)]\n",
    "    for df4_n in df[3].index.str[ic:].values:\n",
    "        tick_counts[3] += [list(tick_labels).index(df4_n)]\n",
    "    cmap = matplotlib.cm.get_cmap('Blues')\n",
    "    p1 = ax.bar(tick_counts[0], df[0]['mean'].values.astype(float), label = 'LPIPS/DISTS Encoder', zorder = -25, color = cmap(0.3))\n",
    "    p2 = ax.bar(tick_counts[1], df[1]['mean'].values.astype(float), label = 'SingleStyle Encoder', zorder = -20, color = cmap(0.5))\n",
    "    #for CPTAC to have the right order of bar graphs:\n",
    "    \n",
    "    if 'THYM' in tick_labels:\n",
    "        p10 = ax.bar([list(tick_labels).index('THYM')], df[0][df[0].index == 'TCGA_THYM']['mean'].values.astype(float), label = 'LPIPS/DISTS Encoder', zorder = -15, color = cmap(0.3))\n",
    "    p3 = ax.bar(tick_counts[2], df[2]['mean'].values.astype(float), label = 'Encoder4Editing', zorder = -10, color = cmap(0.7))\n",
    "    p4 = ax.bar(tick_counts[3], df[3]['mean'].values.astype(float), label = 'HistoXGAN Encoder', zorder = -5, color = cmap(0.9))\n",
    "    \n",
    "#plt.bar(tick_counts_CPTAC, df_cptac[0].values.astype(float), label = '')\n",
    "    ax.set_xticks([x for x in tick_counts[0]])\n",
    "    ax.set_xticklabels(tick_labels, rotation=90)\n",
    "    ax.errorbar(tick_counts[0], df[0]['mean'].values.astype(float), yerr=df[0]['stderr'].astype(float), fmt='none', color='black', capsize=3, zorder = -25)\n",
    "    ax.errorbar(tick_counts[1], df[1]['mean'].values.astype(float), yerr=df[1]['stderr'].astype(float), fmt='none', color='black', capsize=3, zorder = -20)    \n",
    "    if 'THYM' in tick_labels:\n",
    "        ax.errorbar([list(tick_labels).index('THYM')], df[0][df[0].index == 'TCGA_THYM']['mean'].values.astype(float), yerr = df[0][df[0].index == 'TCGA_THYM']['stderr'].astype(float), fmt='none', color='black', capsize = 3, zorder = -15)\n",
    "    ax.errorbar(tick_counts[2], df[2]['mean'].values.astype(float), yerr=df[2]['stderr'].astype(float), fmt='none', color='black', capsize=3, zorder = -10)\n",
    "    ax.errorbar(tick_counts[3], df[3]['mean'].values.astype(float), yerr=df[3]['stderr'].astype(float), fmt='none', color='black', capsize=3, zorder = -5)\n",
    "    ax.set_xlabel('Cancer Subtype, ' + dataset)\n",
    "    if prefix == \"RETCCL\":\n",
    "        ax.set_ylim([0, 0.029])\n",
    "    else:\n",
    "        ax.set_ylim([0, 0.095])\n",
    "    if dataset == 'TCGA':\n",
    "        ax.set_ylabel('L1 Loss')\n",
    "        leg = None\n",
    "        if True and 'THYM' in tick_labels:\n",
    "            leg = ax.legend([(p1, p10), p2, p3, p4], ['LPIPS/DISTS Encoder', 'SingleStyle Encoder', 'Encoder4Editing', 'HistoXGAN Encoder'], loc = 'upper left'\n",
    "                           )#handler_map={tuple: HandlerTuple(ndivide=None)})\n",
    "        else:\n",
    "            leg = ax.legend(loc = 'upper left', facecolor = 'white')\n",
    "        for lh in leg.legendHandles: \n",
    "            lh.set_alpha(1)\n",
    "        leg.get_frame().set_alpha(1)\n",
    "    else:\n",
    "        ax.tick_params(axis = 'y', left = False)\n",
    "\n",
    "bar_plot(axs[0], [df1_tcga, df2_tcga, df3_tcga, df4_tcga], dataset = 'TCGA')\n",
    "bar_plot(axs[1], [df1_cptac, df2_cptac, df3_cptac, df4_cptac], dataset = 'CPTAC')\n",
    "#plt.setp(axs[1].get_yticks(), visible=False)\n",
    "#subf.subplots_adjust(wspace=0.05, hspace=0)\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open(PROJECT_DIR + '/FINAL_IMAGES/img_display_cptac.pkl', 'rb') as f:\n",
    "    imgs_final = pickle.load(f)\n",
    "    \n",
    "#imgs_final = {}\n",
    "imgs = []\n",
    "for img in imgs_final:\n",
    "    imgs += [imgs_final[img]]\n",
    "axs2 = subfigs[1].subplots(len(imgs[0]), len(imgs)) #, dpi = 300, figsize = (10, 10/8*5))#(2*len(imgs), 2*len(imgs[0])))\n",
    "col = 0\n",
    "for img_name in imgs_final:\n",
    "    img_col = imgs_final[img_name]\n",
    "    row = 0\n",
    "    for img in img_col:\n",
    "        axs2[row][col].imshow(img)\n",
    "        #axs[col][row].spines['right'].set_visible(False)\n",
    "        #axs[col][row].spines['top'].set_visible(False)\n",
    "        #axs[col][row].spines['left'].set_visible(False)\n",
    "        #axs[col][row].spines['bottom'].set_visible(False)\n",
    "        axs2[row][col].set_xticks([])\n",
    "        axs2[row][col].set_yticks([])\n",
    "        axs2[row][col].xaxis.set_label_position('top')\n",
    "        axs2[row][col].set_aspect('auto')\n",
    "        row = row + 1\n",
    "        \n",
    "    str_name = img_name[6:]\n",
    "    str_name = str_name.replace(\"_NO_ROI\", \"\")\n",
    "    str_name = str_name.replace(\"COADREAD\", \"COAD\")\n",
    "    axs2[0][col].set_xlabel(str_name)\n",
    "    col = col + 1\n",
    "axs2[0][0].set_ylabel(\"Original\")\n",
    "axs2[1][0].set_ylabel(\"LPIPS / DISTS\")\n",
    "axs2[2][0].set_ylabel(\"Single Layer\")\n",
    "axs2[3][0].set_ylabel(\"Encoder4Editing\")\n",
    "axs2[4][0].set_ylabel(\"HistoXGAN\")\n",
    "#plt.tight_layout()\n",
    "\n",
    "subfigs[1].subplots_adjust(left = 0, top = 1, right = 1, bottom = 0, wspace=-0.1, hspace=0)\n",
    "subfigs[0].subplots_adjust(left = 0.03, top = 1, bottom = 0.3, wspace = 0.07)\n",
    "\n",
    "subfigs[0].text(-0.01,1,\"A\", zorder = 30, clip_on = False, weight='bold' )\n",
    "subfigs[1].text(-0.01,1.01,\"B\", zorder = 30, clip_on = False, weight='bold')\n",
    "\n",
    "plt.savefig(PROJECT_DIR + \"/pub_figures/fig1_\" + prefix + \".svg\")\n",
    "plt.savefig(PROJECT_DIR + \"/pub_figures/fig1_\"  + prefix + \".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da5f5bd",
   "metadata": {},
   "source": [
    "### Supplemental Figure 2 - CTransPath Examples and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92774b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"RETCCL\"\n",
    "df1 = pd.read_csv(PROJECT_DIR + \"/MERGEDLOSS/\" + prefix + \"LPIPSDISTS.csv\", index_col = 0)\n",
    "df2 = pd.read_csv(PROJECT_DIR + \"/MERGEDLOSS/SIMPLE\" + prefix + \".csv\", index_col = 0)\n",
    "df3 = pd.read_csv(PROJECT_DIR + \"/MERGEDLOSS/E4E\" + prefix + \".csv\", index_col = 0)\n",
    "df4 = pd.read_csv(PROJECT_DIR + \"/MERGEDLOSS/\" + prefix + \"GAN.csv\", index_col = 0)\n",
    "df1_tcga = df1[df1.index.str.contains(\"TCGA\")]\n",
    "df1_cptac= df1[df1.index.str.contains(\"CPTAC\")]\n",
    "df2_tcga = df2[df2.index.str.contains(\"TCGA\")]\n",
    "df2_cptac = df2[df2.index.str.contains(\"CPTAC\")]\n",
    "df3_tcga = df3[df3.index.str.contains(\"TCGA\")]\n",
    "df3_cptac = df3[df3.index.str.contains(\"CPTAC\")]\n",
    "df4_tcga = df4[df4.index.str.contains(\"TCGA\")]\n",
    "df4_cptac = df4[df4.index.str.contains(\"CPTAC\")]\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(10, 12), dpi = 300)\n",
    "\n",
    "subfigs = fig.subfigures(2, 1)\n",
    "\n",
    "axs = subfigs[0].subplots(1, 2, sharey = True,  gridspec_kw= {'width_ratios': [3.2, 1]})\n",
    "\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "\n",
    "def bar_plot(ax, df, dataset):\n",
    "\n",
    "    ic = 6\n",
    "    if dataset == 'TCGA':\n",
    "        ic = 5\n",
    "    tick_labels = df[0].index.str[ic:].values\n",
    "    tick_labels.sort()\n",
    "    tick_labels = tick_labels\n",
    "    tick_counts = [list(range(len(df[0].index.values))), [], [], []]\n",
    "    tick_counts[0] = [x for x in tick_counts[0]]\n",
    "    for df2_n in df[1].index.str[ic:].values:\n",
    "        tick_counts[1] += [list(tick_labels).index(df2_n)]\n",
    "    for df3_n in df[2].index.str[ic:].values:\n",
    "        tick_counts[2] += [list(tick_labels).index(df3_n)]\n",
    "    for df4_n in df[3].index.str[ic:].values:\n",
    "        tick_counts[3] += [list(tick_labels).index(df4_n)]\n",
    "    cmap = matplotlib.cm.get_cmap('Blues')\n",
    "    p1 = ax.bar(tick_counts[0], df[0]['mean'].values.astype(float), label = 'LPIPS/DISTS Encoder', zorder = -2, color = cmap(0.3))\n",
    "    p2 = ax.bar(tick_counts[1], df[1]['mean'].values.astype(float), label = 'SingleStyle Encoder', zorder = -1, color = cmap(0.5))\n",
    "    #for RETCCL to have the right order of bar graphs:\n",
    "    if dataset == 'TCGA':\n",
    "        tl_l = []\n",
    "        tl_m = []\n",
    "        for s in ['CESC', 'CHOL', 'COADREAD', 'DLBC', 'HNSC', 'KIRP', 'LGG', 'LUAD', 'LUSC', 'OV', 'PCPG', 'PRAD', 'SARC', 'SKCM', 'TGCT', 'THCA', 'UCEC', 'UCS' ,'UVM']:\n",
    "            tl_l += [list(tick_labels).index(s)]\n",
    "            tl_m += [df[0][df[0].index == 'TCGA_' + s]['mean'].values.astype(float)[0]]\n",
    "    \n",
    "    if dataset == 'CPTAC':\n",
    "        tl_l = []\n",
    "        tl_m = []\n",
    "        for s in ['LUSC', 'PAAD', 'UCEC']:\n",
    "            tl_l += [list(tick_labels).index(s)]\n",
    "            tl_m += [df[0][df[0].index == 'CPTAC_' + s]['mean'].values.astype(float)[0]]\n",
    "    \n",
    "    p10 = ax.bar(tl_l, tl_m, label = 'LPIPS/DISTS Encoder', zorder = 0, color = cmap(0.3))\n",
    "\n",
    "\n",
    "    p3 = ax.bar(tick_counts[2], df[2]['mean'].values.astype(float), label = 'Encoder4Editing', zorder = 15, color = cmap(0.7))\n",
    "    p4 = ax.bar(tick_counts[3], df[3]['mean'].values.astype(float), label = 'HistoXGAN Encoder', zorder = 20, color = cmap(0.9))\n",
    "    \n",
    "#plt.bar(tick_counts_CPTAC, df_cptac[0].values.astype(float), label = '')\n",
    "    ax.set_xticks([x for x in tick_counts[0]])\n",
    "    ax.set_xticklabels(tick_labels, rotation=90)\n",
    "    ax.errorbar(tick_counts[0], df[0]['mean'].values.astype(float), yerr=df[0]['stderr'].astype(float), fmt='none', color='black', capsize=3, zorder = -2)\n",
    "    ax.errorbar(tick_counts[1], df[1]['mean'].values.astype(float), yerr=df[1]['stderr'].astype(float), fmt='none', color='black', capsize=3, zorder = -1)    \n",
    "    if dataset == 'TCGA':\n",
    "        tl_l = []\n",
    "        tl_m = []\n",
    "        tl_e = []\n",
    "        for s in ['CESC', 'CHOL', 'COADREAD', 'DLBC', 'HNSC', 'KIRP', 'LGG', 'LUAD', 'LUSC', 'OV', 'PCPG', 'PRAD', 'SARC', 'SKCM', 'TGCT', 'THCA', 'UCEC', 'UCS' ,'UVM']:\n",
    "            tl_l += [list(tick_labels).index(s)]\n",
    "            tl_m += [df[0][df[0].index == 'TCGA_' + s]['mean'].values.astype(float)[0]]\n",
    "            tl_e += [df[0][df[0].index == 'TCGA_' + s]['stderr'].astype(float)[0]]\n",
    "        ax.errorbar(tl_l, tl_m, yerr = tl_e, fmt='none', color='black', capsize = 3, zorder = 0)\n",
    "    if dataset == 'CPTAC':\n",
    "        tl_l = []\n",
    "        tl_m = []\n",
    "        tl_e = []\n",
    "        for s in ['LUSC', 'PAAD', 'UCEC']:\n",
    "            tl_l += [list(tick_labels).index(s)]\n",
    "            tl_m += [df[0][df[0].index == 'CPTAC_' + s]['mean'].values.astype(float)[0]]\n",
    "            tl_e += [df[0][df[0].index == 'CPTAC_' + s]['stderr'].astype(float)[0]]\n",
    "        ax.errorbar(tl_l, tl_m, yerr = tl_e, fmt='none', color='black', capsize = 3, zorder = 0)\n",
    "    ax.errorbar(tick_counts[2], df[2]['mean'].values.astype(float), yerr=df[2]['stderr'].astype(float), fmt='none', color='black', capsize=3, zorder = 15)\n",
    "    ax.errorbar(tick_counts[3], df[3]['mean'].values.astype(float), yerr=df[3]['stderr'].astype(float), fmt='none', color='black', capsize=3, zorder = 20)\n",
    "    ax.set_xlabel('Cancer Subtype, ' + dataset)\n",
    "    ax.set_ylim([0, 0.029])\n",
    "    if dataset == 'TCGA':\n",
    "        ax.set_ylabel('L1 Loss')\n",
    "        leg = None\n",
    "        if True:\n",
    "            leg = ax.legend([(p1, p10), p2, p3, p4], ['LPIPS/DISTS Encoder', 'SingleStyle Encoder', 'Encoder4Editing', 'HistoXGAN Encoder'],\n",
    "                           loc = 'upper left', facecolor = 'white')#handler_map={tuple: HandlerTuple(ndivide=None)})\n",
    "        else:\n",
    "            leg = ax.legend(loc = 'upper left', facecolor = 'white')\n",
    "        for lh in leg.legendHandles: \n",
    "            lh.set_alpha(1)\n",
    "        leg.get_frame().set_alpha(1)\n",
    "    else:\n",
    "        ax.tick_params(axis = 'y', left = False)\n",
    "\n",
    "bar_plot(axs[0], [df1_tcga, df2_tcga, df3_tcga, df4_tcga], dataset = 'TCGA')\n",
    "bar_plot(axs[1], [df1_cptac, df2_cptac, df3_cptac, df4_cptac], dataset = 'CPTAC')\n",
    "#plt.setp(axs[1].get_yticks(), visible=False)\n",
    "\n",
    "import pickle\n",
    "with open(PROJECT_DIR + '/FINAL_IMAGES/img_display_cptac_retccl.pkl', 'rb') as f:\n",
    "    imgs_final = pickle.load(f)\n",
    "    \n",
    "#imgs_final = {}\n",
    "imgs = []\n",
    "for img in imgs_final:\n",
    "    imgs += [imgs_final[img]]\n",
    "axs2 = subfigs[1].subplots(len(imgs[0]), len(imgs)) #, dpi = 300, figsize = (10, 10/8*5))#(2*len(imgs), 2*len(imgs[0])))\n",
    "col = 0\n",
    "for img_name in imgs_final:\n",
    "    img_col = imgs_final[img_name]\n",
    "    row = 0\n",
    "    for img in img_col:\n",
    "        axs2[row][col].imshow(img)\n",
    "        #axs[col][row].spines['right'].set_visible(False)\n",
    "        #axs[col][row].spines['top'].set_visible(False)\n",
    "        #axs[col][row].spines['left'].set_visible(False)\n",
    "        #axs[col][row].spines['bottom'].set_visible(False)\n",
    "        axs2[row][col].set_xticks([])\n",
    "        axs2[row][col].set_yticks([])\n",
    "        axs2[row][col].xaxis.set_label_position('top')\n",
    "        axs2[row][col].set_aspect('auto')\n",
    "        row = row + 1\n",
    "        \n",
    "    str_name = img_name[6:]\n",
    "    str_name = str_name.replace(\"_NO_ROI\", \"\")\n",
    "    str_name = str_name.replace(\"COADREAD\", \"COAD\")\n",
    "    axs2[0][col].set_xlabel(str_name)\n",
    "    col = col + 1\n",
    "axs2[0][0].set_ylabel(\"Original\")\n",
    "axs2[1][0].set_ylabel(\"LPIPS / DISTS\")\n",
    "axs2[2][0].set_ylabel(\"SingleStyle\")\n",
    "axs2[3][0].set_ylabel(\"Encoder4Editing\")\n",
    "axs2[4][0].set_ylabel(\"HistoXGAN\")\n",
    "#plt.tight_layout()\n",
    "\n",
    "subfigs[1].subplots_adjust(left = 0, top = 1, right = 1, bottom = 0, wspace=-0.1, hspace=0)\n",
    "subfigs[0].subplots_adjust(left = 0.03, top = 1, bottom = 0.3, wspace = 0.07)\n",
    "\n",
    "subfigs[0].text(-0.01,1,\"A\", zorder = 30, clip_on = False, weight='bold' )\n",
    "subfigs[1].text(-0.01,1.01,\"B\", zorder = 30, clip_on = False, weight='bold')\n",
    "\n",
    "plt.savefig(PROJECT_DIR + \"/pub_figures/fig1_retccl.svg\")\n",
    "plt.savefig(PROJECT_DIR + \"/pub_figures/fig1_retccl.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668493d1",
   "metadata": {},
   "source": [
    "# Figure 3 / Supplemental Figure 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db29f0",
   "metadata": {},
   "source": [
    "## These figures illustrate using the mean difference in features to transition between states of grade, subtype, and gene expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d33e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following are helper functions for interpolation and the statistical calculations for correlation between predicted\n",
    "#grade / subtype / gene expression for real / generated images\n",
    "\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "with dnnlib.util.open_url(PROJECT_DIR + '/FINAL_MODELS/CTransPath/snapshot.pkl') as f:\n",
    "    G = legacy.load_network_pkl(f)['G_ema'].to(device)\n",
    "\n",
    "def vector_interpolate(\n",
    "    G: torch.nn.Module,\n",
    "    z: torch.tensor,\n",
    "    z2: torch.tensor,\n",
    "    device: torch.device,\n",
    "    steps: int = 100\n",
    "):\n",
    "    for interp_idx in range(steps):\n",
    "        torch_interp = torch.tensor(z - z2 + 2*interp_idx/steps*z2).to(device)\n",
    "        img = G(torch_interp, 0, noise_mode ='const')\n",
    "        img = (img + 1) * (255/2)\n",
    "        img = img.permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
    "        yield img\n",
    "        \n",
    "def generate_images(vector_z, vector_z2, prefix = 'test'):\n",
    "    z = torch.tensor(vector_z).to(device)\n",
    "    z2 = torch.tensor(vector_z2).to(device)\n",
    "    img_array = []\n",
    "    generator = vector_interpolate(G, z, z2, device = device)\n",
    "    for interp_idx, img in enumerate(generator):\n",
    "        img_array += [img]\n",
    "    return img_array\n",
    "\n",
    "def get_log_features(df, col, name):\n",
    "    y = df[[col]].values\n",
    "    feat_cols = list(df.columns.values)\n",
    "    feat_cols = [f for f in feat_cols if 'Feature_' in f]\n",
    "    #print(feat_cols)\n",
    "    X = df[feat_cols]\n",
    "    vector_list = X.loc[0, :].values.tolist()        \n",
    "    clf = LogisticRegression().fit(X, y)\n",
    "    return vector_list, clf.coef_\n",
    "\n",
    "\n",
    "def strround(s, r = 2):\n",
    "    return str(round(s, r))\n",
    "\n",
    "def r_to_z(r):\n",
    "    return math.log((1 + r) / (1 - r)) / 2.0\n",
    "\n",
    "def z_to_r(z):\n",
    "    e = math.exp(2 * z)\n",
    "    return((e - 1) / (e + 1))\n",
    "\n",
    "def r_confidence_interval(r, alpha, n):\n",
    "    z = r_to_z(r)\n",
    "    se = 1.0 / math.sqrt(n - 3)\n",
    "    z_crit = stats.norm.ppf(1 - alpha/2)  # 2-tailed z critical value\n",
    "\n",
    "    lo = z - z_crit * se\n",
    "    hi = z + z_crit * se\n",
    "\n",
    "    # Return a sequence\n",
    "    return (z_to_r(lo), z_to_r(hi))\n",
    "def SuperScriptinate(number):\n",
    "    return number.replace('0','⁰').replace('1','¹').replace('2','²').replace('3','³').replace('4','⁴').replace('5','⁵').replace('6','⁶').replace('7','⁷').replace('8','⁸').replace('9','⁹').replace('-','⁻')\n",
    "\n",
    "def sci_notation(number, sig_fig=2):\n",
    "    ret_string = \"{0:.{1:d}e}\".format(number, sig_fig)\n",
    "    a,b = ret_string.split(\"e\")\n",
    "    b = int(b)         # removed leading \"+\" and strips leading zeros too.\n",
    "    return a + \" x 10\" + SuperScriptinate(str(b))\n",
    "\n",
    "\n",
    "#Load compare group will perform calculations and plot the correlation between predictions from real image tiles\n",
    "#versus generated versions for those same image tiles\n",
    "#dfs1 and dfs2 are file paths to the 'patient_predictions.csv' saved in the folder\n",
    "#generated when evaluating models in the Slideflow software.\n",
    "#For k-fold cross validation (i.e. the internal evaluation of the models in TCGA) these variables should be arrays\n",
    "#representing a list of files for the predictions in the held out test set for each cross fold\n",
    "#For convenience and reproducibility we have saved these predictions in the /FINAL_PREDICTIONS/ folder and loaded them\n",
    "#automatically\n",
    "def load_compare_group(dfs1 = None, dfs2 = None, title = None, ax = None, read_csv = False, pred_only = False, pred_df = None, color_df = None, pred_class_col = None, pred_class_opts = None, class_names = None, xlabel = False, ylabel = False, unknown_name = \"\", regen = False):\n",
    "    if not regen and os.path.isfile(PROJECT_DIR + \"/FINAL_PREDICTIONS/\" + str(title) + \"_\" + str(class_names[1]) + \"_compare_df.pkl\"):\n",
    "        with open(PROJECT_DIR + \"/FINAL_PREDICTIONS/\" + str(title) + \"_\" + str(class_names[1]) + \"_compare_df.pkl\", 'rb') as f:\n",
    "            df1 = pickle.load(f)\n",
    "    else:\n",
    "        df_1 = []\n",
    "        df_2 = []\n",
    "        if read_csv:\n",
    "            for f in dfs1:\n",
    "                df_1 += [pd.read_csv(f)]\n",
    "            for f in dfs2:\n",
    "                df_2 += [pd.read_csv(f)] \n",
    "                df_2[len(df_2) - 1]['load_group'] = len(df_2)\n",
    "\n",
    "        else:\n",
    "            for f in dfs1:\n",
    "                df_1 += [pd.read_parquet(f)]\n",
    "            for f in dfs2:\n",
    "                df_2 += [pd.read_parquet(f)]\n",
    "                df_2[len(df_2) - 1]['load_group'] = len(df_2)\n",
    "\n",
    "        df1 = pd.concat(df_1)\n",
    "        df2 = pd.concat(df_2)\n",
    "        df1 = df1.merge(df2, on='patient', how='inner')\n",
    "        if pred_df:\n",
    "            df3 = pd.read_csv(pred_df)\n",
    "            df1 = df1.merge(df3[['patient', pred_class_col]], on='patient', how='left')\n",
    "            df1 = df1[df1[pred_class_col].isin(pred_class_opts)]\n",
    "            df1['group'] = 0\n",
    "            df1.loc[df1[pred_class_col] == pred_class_opts[1], 'group'] = 1\n",
    "        if color_df:\n",
    "            from sklearn.preprocessing import QuantileTransformer\n",
    "            qt = QuantileTransformer(n_quantiles=1000, random_state=0)\n",
    "            df3 = pd.read_csv(color_df)\n",
    "            df1 = df1.merge(df3[['patient', pred_class_col]], on='patient', how='left')\n",
    "            df1[pred_class_col] = 100 * qt.fit_transform(-1 * df1[[pred_class_col]])\n",
    "            #df1[pred_class_col] = df1[pred_class_col].apply(lambda x: qt.transform(x))\n",
    "        with open(PROJECT_DIR + \"/FINAL_PREDICTIONS/\" + str(title) + \"_\" + str(class_names[1]) + \"_compare_df.pkl\", 'wb') as f:\n",
    "            pickle.dump(df1, f)\n",
    "    roc = \"N/A\"\n",
    "    prc = \"N/A\"\n",
    "    roc_gen = \"N/A\"\n",
    "    prc_gen = \"N/A\"\n",
    "    from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "    if ax:\n",
    "        if pred_only:\n",
    "            if pred_df:\n",
    "                im = ax.scatter(df1[df1.group == 0].iloc[:, 2], df1[df1.group == 0].iloc[:, 5], label = \"True \" +  class_names[0])\n",
    "                im = ax.scatter(df1[df1.group == 1].iloc[:, 2], df1[df1.group == 1].iloc[:, 5], label = \"True \" +  class_names[1])\n",
    "                roc = strround(roc_auc_score(df1[\"group\"], df1.iloc[:, 2]))\n",
    "                roc_gen = strround(roc_auc_score(df1[\"group\"], df1.iloc[:, 5]))\n",
    "                prc = strround(average_precision_score(df1[\"group\"], df1.iloc[:, 2]))\n",
    "                prc_gen = strround(average_precision_score(df1[\"group\"], df1.iloc[:, 5]))\n",
    "            elif color_df:\n",
    "                ra, rb = stats.pearsonr(df1.iloc[:,2].values, df1[pred_class_col])\n",
    "                rc, rd = stats.pearsonr(df1.iloc[:,5].values, df1[pred_class_col])\n",
    "                la, ha = r_confidence_interval(ra, 0.05, len(df1.index))\n",
    "                lc, hc = r_confidence_interval(rc, 0.05, len(df1.index))\n",
    "\n",
    "                roc = strround(ra, 2) + \" (\" + strround(la, 2) + \" - \" + strround(ha, 2) + \")\"\n",
    "                prc = strround(rb, 2)\n",
    "                \n",
    "                roc_gen = strround(rc, 2) + \" (\" + strround(lc, 2) + \" - \" + strround(hc, 2) + \")\"\n",
    "                prc_gen = strround(rd, 2)\n",
    "                \n",
    "                im = ax.scatter(df1.iloc[:, 2], df1.iloc[:, 5], c=df1[pred_class_col], cmap='Blues')\n",
    "            else:\n",
    "                im = ax.scatter(df1.iloc[:, 2], df1.iloc[:, 5], label = 'Unknown ' + unknown_name, color = 'gray')\n",
    "        else:\n",
    "            roc = strround(roc_auc_score(df1.iloc[:,3], df1.iloc[:, 2]))\n",
    "            roc_gen = strround(roc_auc_score(df1.iloc[:,3], df1.iloc[:, 5]))\n",
    "            prc = strround(average_precision_score(df1.iloc[:,3], df1.iloc[:, 2]))\n",
    "            prc_gen = strround(average_precision_score(df1.iloc[:,3], df1.iloc[:, 5]))\n",
    "            im = ax.scatter(df1[df1.iloc[:,3] == 0].iloc[:, 2], df1[df1.iloc[:,3] == 0].iloc[:, 5], label = \"True \" +  class_names[0])\n",
    "            im = ax.scatter(df1[df1.iloc[:,3] == 1].iloc[:, 2], df1[df1.iloc[:,3] == 1].iloc[:, 5], label = \"True \" +  class_names[1])\n",
    "        if xlabel:\n",
    "            ax.set_xlabel(\"Prediction, Real Image\")\n",
    "        else:\n",
    "            ax.xaxis.set_ticks_position('none')\n",
    "        if ylabel:\n",
    "            ax.set_ylabel(\"Prediction, GAN Image\")\n",
    "        else:\n",
    "            ax.yaxis.set_ticks_position('none')\n",
    "        if title:\n",
    "            ax.set_title(title)\n",
    "\n",
    "        p = 0\n",
    "        if pred_only and not pred_df and not color_df:\n",
    "            r, p = stats.pearsonr(df1.iloc[:,3].values, df1.iloc[:,6].values)\n",
    "        else:\n",
    "            r, p = stats.pearsonr(df1.iloc[:,2].values, df1.iloc[:,5].values)\n",
    "        l, h = r_confidence_interval(r, 0.05, len(df1.index))\n",
    "        ax.plot([0,1], np.poly1d(np.polyfit(df1.iloc[:, 2], df1.iloc[:, 5], 1))([0,1]), label = \"r = \" + strround(r,2) + \" (\" + strround(l, 2) + \" - \" + strround(h, 2) + \")\")\n",
    "        ax.legend(loc = 'upper left')\n",
    "        grade_str = \"N/A\"\n",
    "        if pred_only and pred_df:\n",
    "            grade_str = round(100 * len(df1[df1.group == 1].index) / len(df1.index), 1)\n",
    "        if not pred_only:\n",
    "            grade_str = round(100 * len(df1[df1.iloc[:, 3] == 1].index) / len(df1.index), 1)\n",
    "        if class_names[1] == 'High Grade':\n",
    "            return [[title.split(\" - \")[1], title.split(\" - \")[0], len(df1), grade_str, strround(r,2) + \" (\" + strround(l, 2) + \" - \" + strround(h, 2) + \")\", strround(r_to_z(r),2), sci_notation(p), roc, prc, roc_gen, prc_gen]]\n",
    "        elif not color_df:\n",
    "            class_str_0 = \"N/A\"\n",
    "            if pred_only and pred_df:\n",
    "                class_str_0 = round(100 * len(df1[df1.group == 0].index) / len(df1.index), 1)\n",
    "            if not pred_only:\n",
    "                class_str_0 = round(100 * len(df1[df1.iloc[:, 3] == 0].index) / len(df1.index), 1)\n",
    "            return [[title.split(\" - \")[1], title.split(\" - \")[0], len(df1), class_names[0], class_str_0, class_names[1], grade_str, strround(r,2) + \" (\" + strround(l, 2) + \" - \" + strround(h, 2) + \")\", strround(r_to_z(r),2), sci_notation(p), roc, prc, roc_gen, prc_gen]]\n",
    "        else:\n",
    "            class_str_0 = \"N/A\"\n",
    "            if pred_only and pred_df:\n",
    "                class_str_0 = round(100 * len(df1[df1.group == 0].index) / len(df1.index), 1)\n",
    "            if not pred_only:\n",
    "                class_str_0 = round(100 * len(df1[df1.iloc[:, 3] == 0].index) / len(df1.index), 1)\n",
    "            return im, [[title.split(\" - \")[1], title.split(\" - \")[0], len(df1), class_names[0], class_str_0, class_names[1], grade_str, strround(r,2) + \" (\" + strround(l, 2) + \" - \" + strround(h, 2) + \")\", strround(r_to_z(r),2), sci_notation(p), roc, prc, roc_gen, prc_gen]]\n",
    "    else:\n",
    "        if pred_only:            \n",
    "            plt.scatter(df1.iloc[:, 2], df1.iloc[:, 5])\n",
    "        else:\n",
    "            plt.scatter(df1[df1.iloc[:,3] == 0].iloc[:, 2], df1[df1.iloc[:,3] == 0].iloc[:, 5], label = \"True \" +  class_names[0])\n",
    "            plt.scatter(df1[df1.iloc[:,3] == 1].iloc[:, 2], df1[df1.iloc[:,3] == 1].iloc[:, 5], label = \"True \" +  class_names[1])\n",
    "        print(df1.corr())\n",
    "        plt.xlabel(\"Prediction, Real Image\")\n",
    "        plt.ylabel(\"Prediction, GAN Image\")\n",
    "        plt.title(title)\n",
    "        if pred_only:   \n",
    "            r = df1.corr().iloc[1,4]\n",
    "        else:\n",
    "            r = df1.corr().iloc[0,3]\n",
    "        l, h = r_confidence_interval(r, 0.05, len(df1.index))\n",
    "        plt.plot([0,1], np.poly1d(np.polyfit(df1.iloc[:, 2], df1.iloc[:, 5], 1))([0,1]), label = \"r = \" + strround(r,2) + \" (\" + strround(l, 2) + \" - \" + strround(h, 2) + \")\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc6d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code generates images along the transition for high / low grade\n",
    "\n",
    "def GRADE_DATASET(dataset, ind, grade_col):\n",
    "    df = pd.read_csv(PROJECT_DIR + \"/PROJECTS/HistoXGAN/SAVED_FEATURES/\" +  dataset.lower() + \"_features_slide.csv\")\n",
    "    df2 = pd.read_csv(PROJECT_DIR + \"/PROJECTS/HistoXGAN/tcga_all_annotations.csv\")\n",
    "    df_mod = pd.read_csv(PROJECT_DIR + \"/PROJECTS/HistoXGAN/SAVED_FEATURES/\" +  dataset.lower() + \"_features_part.csv\")\n",
    "    feat_cols = list(df.columns.values)\n",
    "    feat_cols = [f for f in feat_cols if 'Feature_' in f]\n",
    "    vector_base = df_mod[feat_cols].loc[ind, :].values.tolist()    \n",
    "    df['patient'] = df['Slide'].str[0:12]\n",
    "    df = df.merge(df2, left_on='patient', right_on='patient', how = 'left')\n",
    "    #df.loc[df[grade_col] == 'GX', 'Grade_Class'] = np.nan\n",
    "    #df.loc[df[grade_col] == '[Not Available]', 'Grade_Class'] = np.nan\n",
    "    df=df.dropna(subset=['high_grade'])\n",
    "    df['Grade_Class'] = 0\n",
    "    df.loc[df.high_grade == 'Y', 'Grade_Class'] = 1\n",
    "    #if dataset == 'PRAD':\n",
    "    #    df.loc[df[grade_col] == 9, 'Grade_Class'] = 1\n",
    "    #else:\n",
    "    #    df.loc[df[grade_col] == 3, 'Grade_Class'] = 1\n",
    "    #    df.loc[df[grade_col] == 'G3', 'Grade_Class'] = 1\n",
    "    #    df.loc[df[grade_col] == 'G4', 'Grade_Class'] = 1\n",
    "    \n",
    "    vector_z, vector_z2 = get_log_features(df, 'Grade_Class', 'Grade_' + dataset)\n",
    "    vector_z = vector_base\n",
    "    return generate_images(vector_z, vector_z2, prefix = 'Grade_' + dataset)\n",
    "\n",
    "img_dict = {}\n",
    "img_dict['BRCA'] = GRADE_DATASET('BRCA', 100, 'Grade')\n",
    "img_dict['PAAD'] = GRADE_DATASET('PAAD', 100, 'histological_grade')\n",
    "img_dict['HNSC'] = GRADE_DATASET('HNSC', 200, 'neoplasm_histologic_grade')\n",
    "img_dict['PRAD'] = GRADE_DATASET('PRAD', 200, 'Clinical_Gleason_sum')\n",
    "\n",
    "\n",
    "f = open(PROJECT_DIR + '/FINAL_IMAGES/img_display_grade_lr.pkl', 'wb')\n",
    "pickle.dump(img_dict, f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3d8561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code generates images along the transition between cancer subtypes\n",
    "\n",
    "def SUBTYPE_DATASET(dataset, ind):\n",
    "    df = pd.read_csv(PROJECT_DIR + \"/PROJECTS/HistoXGAN/SAVED_FEATURES/\" +  dataset.lower() + \"_features_slide.csv\")\n",
    "    df2 = pd.read_csv(PROJECT_DIR + \"/PROJECTS/HistoXGAN/tcga_all_annotations.csv\")\n",
    "    if dataset == 'LUNG':\n",
    "        df_mod = pd.read_csv(PROJECT_DIR + \"/PROJECTS/HistoXGAN/SAVED_FEATURES/luad_features_part.csv\")    \n",
    "    elif dataset == 'KIDNEY':\n",
    "        df_mod = pd.read_csv(PROJECT_DIR + \"/PROJECTS/HistoXGAN/SAVED_FEATURES/kirp_features_part.csv\")    \n",
    "    else:\n",
    "        df_mod = pd.read_csv(PROJECT_DIR + \"/PROJECTS/HistoXGAN/SAVED_FEATURES/\" +  dataset.lower() + \"_features_part.csv\")\n",
    "\n",
    "    feat_cols = list(df.columns.values)\n",
    "    feat_cols = [f for f in feat_cols if 'Feature_' in f]\n",
    "    vector_base = df_mod[feat_cols].loc[ind, :].values.tolist()    \n",
    "\n",
    "    df['patient'] = df['Slide'].str[0:12]\n",
    "    if dataset == 'LUNG':\n",
    "        df2['patient'] = df2['patient'].str[0:12]\n",
    "    df = df.merge(df2, left_on='patient', right_on='patient', how = 'left')\n",
    "    df['Subtype'] = np.nan\n",
    "    if dataset == 'BRCA':\n",
    "        df.loc[df['2016 Histology Annotations'] == 'Invasive ductal carcinoma', 'Subtype'] = 0\n",
    "        df.loc[df['2016 Histology Annotations'] == 'Invasive lobular carcinoma', 'Subtype'] = 1\n",
    "    elif dataset == 'LUNG':    \n",
    "        df=df.dropna(subset=['project_id'])\n",
    "        df['Subtype'] = 0\n",
    "        df.loc[df['project_id'] == 'TCGA-LUSC', 'Subtype'] = 1\n",
    "    elif dataset == 'ESCA':\n",
    "        df.loc[df['histological_type'] == \"Esophagus Adenocarcinoma, NOS\", 'Subtype'] = 0\n",
    "        df.loc[df['histological_type'] == \"Esophagus Squamous Cell Carcinoma\", 'Subtype'] = 1\n",
    "    elif dataset == 'KIDNEY':\n",
    "        df.loc[df['project_id'] == 'TCGA-KIRC', 'Subtype'] = 0\n",
    "        df.loc[df['project_id'] == 'TCGA-KIRP', 'Subtype'] = 1\n",
    "        \n",
    "    df=df.dropna(subset=['Subtype'])\n",
    "    \n",
    "    vector_z, vector_z2 = get_log_features(df, 'Subtype', 'Subtype_' + dataset)\n",
    "    vector_z = vector_base\n",
    "    return generate_images(vector_z, vector_z2, prefix = 'Subtype_' + dataset)\n",
    "\n",
    "\n",
    "img_dict = {}\n",
    "img_dict['BRCA'] = SUBTYPE_DATASET('BRCA', 100)\n",
    "img_dict['LUNG'] = SUBTYPE_DATASET('LUNG', 100)\n",
    "img_dict['ESCA'] = SUBTYPE_DATASET('ESCA', 200)\n",
    "img_dict['KIDNEY'] = SUBTYPE_DATASET('KIDNEY', 6)\n",
    "\n",
    "f = open(PROJECT_DIR + '/FINAL_IMAGES/img_display_subtype_lr.pkl', 'wb')\n",
    "pickle.dump(img_dict, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61116798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code generates images along the transition for high / low gene expression\n",
    "\n",
    "def BRCA_gene(gene = \"CD3G\", ind = 100):\n",
    "    df = pd.read_csv(PROJECT_DIR + \"/PROJECTS/HistoXGAN/SAVED_FEATURES/brca_features_slide.csv\")\n",
    "    df2 = pd.read_csv(PROJECT_DIR + \"/PROJECTS/HistoXGAN/tcga_all_annotations.csv\")\n",
    "    df_mod = pd.read_csv(PROJECT_DIR + \"/PROJECTS/HistoXGAN/SAVED_FEATURES/brca_features_part.csv\")\n",
    "    feat_cols = list(df.columns.values)\n",
    "    feat_cols = [f for f in feat_cols if 'Feature_' in f]\n",
    "    vector_base = df_mod[feat_cols].loc[ind, :].values.tolist()    \n",
    "    df['patient'] = df['Slide'].str[0:12]\n",
    "    df = df.merge(df2, left_on='patient', right_on='patient', how = 'left')\n",
    "    df[gene] = np.nan\n",
    "    df.loc[df[gene + '_class'] == 'L', gene] = 0\n",
    "    df.loc[df[gene + '_class'] == 'H', gene] = 1\n",
    "    df=df.dropna(subset=[gene])\n",
    "    vector_z, vector_z2 = get_log_features(df, gene, gene + '_BRCA')\n",
    "    vector_z = vector_base\n",
    "    return generate_images(vector_z, vector_z2, prefix = gene + '_BRCA')\n",
    "\n",
    "img_dict = {}#6 is good also #39 or 40\n",
    "img_dict['CD3G'] = BRCA_gene('CD3G')\n",
    "img_dict['COL1A1'] = BRCA_gene('COL1A1')\n",
    "img_dict['MKI67'] = BRCA_gene('MKI67')\n",
    "img_dict['EPCAM'] = BRCA_gene('EPCAM')\n",
    "\n",
    "f = open(PROJECT_DIR + '/FINAL_IMAGES/img_display_gene_lr.pkl', 'wb')\n",
    "pickle.dump(img_dict, f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff99599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code loads the saved images for grade transition, and also loads the results of models trained to predict grade\n",
    "#to compare predictions for real slide images vs slide images regenerated with HistoXGAN\n",
    "\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "with open(PROJECT_DIR + '/FINAL_IMAGES/img_display_grade_lr.pkl', 'rb') as f:\n",
    "    img_dict = pickle.load(f)\n",
    "    \n",
    "fig = plt.figure(figsize=(20, 8), dpi = 300)\n",
    "\n",
    "subfigs = fig.subfigures(1, 2, width_ratios=[14, 6])\n",
    "\n",
    "axs = subfigs[1].subplots(4, 2, sharex = True, sharey = True)\n",
    "\n",
    "result_table = []\n",
    "result_table += load_compare_group(\n",
    "    title = \"BRCA - TCGA\",\n",
    "    ax = axs[0][0],\n",
    "    class_names = ['Low Grade', 'High Grade'],\n",
    "    ylabel = \"BRCA\"\n",
    ")\n",
    "\n",
    "result_table += load_compare_group(\n",
    "    title = \"PAAD - TCGA\",\n",
    "    ax = axs[1][0],\n",
    "    class_names = ['Low Grade', 'High Grade'],\n",
    "    ylabel = \"PAAD\"\n",
    ")\n",
    "\n",
    "result_table += load_compare_group(\n",
    "    title = \"PRAD - TCGA\",\n",
    "    ax = axs[3][0],\n",
    "    class_names = ['Low Grade', 'High Grade'],\n",
    "    ylabel = \"PRAD\",\n",
    "    xlabel = True\n",
    ")\n",
    "result_table += load_compare_group(\n",
    "    title = \"HNSC - TCGA\",\n",
    "    ax = axs[2][0],\n",
    "    class_names = ['Low Grade', 'High Grade'],\n",
    "    ylabel = \"HNSC\"\n",
    ")\n",
    "\n",
    "result_table += load_compare_group(\n",
    "    title = \"BRCA - CPTAC\",\n",
    "    ax = axs[0][1],\n",
    "    class_names = ['Low Grade', 'High Grade'],\n",
    "    read_csv = True,\n",
    "    pred_only = True,\n",
    "    unknown_name = \"Grade\")\n",
    "\n",
    "result_table += load_compare_group(\n",
    "    title = \"PAAD - CPTAC\",\n",
    "    class_names = ['Low Grade', 'High Grade'],\n",
    "    ax = axs[1][1]\n",
    ")\n",
    "result_table += load_compare_group(\n",
    "    title = \"HNSC - CPTAC\",\n",
    "    ax = axs[2][1],\n",
    "    class_names = ['Low Grade', 'High Grade'],\n",
    "    read_csv = True,\n",
    "    pred_only = True,\n",
    "    xlabel = True,\n",
    "    unknown_name = \"Grade\")\n",
    "\n",
    "axs[3][1].set_visible(False)\n",
    "\n",
    "df = pd.DataFrame(result_table, columns = ['Dataset', 'Subtype', 'n', 'High Grade (%)', 'Pearson r', 'z statistic', 'p-value, correlation', 'AUROC', 'AP', 'AUROC Gen', 'AUPRC Gen'])\n",
    "from IPython.display import display\n",
    "display(df)\n",
    "\n",
    "\n",
    "img_include = 7\n",
    "\n",
    "axs2 = subfigs[0].subplots(len(img_dict), img_include)\n",
    "\n",
    "row_loc = {\n",
    "    'BRCA':[20,30,40,50,60,70,80],\n",
    "    'HNSC':[20,30,40,50,60,70,80],\n",
    "    'PAAD':[20,30,40,50,60,70,80],\n",
    "    'PRAD':[20,30,40,50,60,70,80],\n",
    "}\n",
    "col = 0\n",
    "for img_name in img_dict:\n",
    "    row = 0\n",
    "    for row_item in row_loc[img_name]:\n",
    "        axs2[col][row].imshow(img_dict[img_name][row_item])\n",
    "        #axs[col][row].spines['right'].set_visible(False)\n",
    "        #axs[col][row].spines['top'].set_visible(False)\n",
    "        #axs[col][row].spines['left'].set_visible(False)\n",
    "        #axs[col][row].spines['bottom'].set_visible(False)\n",
    "        axs2[col][row].set_xticks([])\n",
    "        axs2[col][row].set_yticks([])\n",
    "        axs2[col][row].xaxis.set_label_position('top')\n",
    "        row = row + 1\n",
    "    str_name = img_name\n",
    "    axs2[col][0].set_ylabel(str_name, size = 18)\n",
    "    col = col + 1\n",
    "plt.tight_layout()\n",
    "subfigs[0].subplots_adjust(left = 0, top = 1, right = 1, bottom = 0, wspace=0, hspace=0)\n",
    "subfigs[1].subplots_adjust(left = 0.2, top = 1.0, bottom = 0, wspace = 0.1, hspace = 0.2)\n",
    "axs2[0][0].annotate(text=\"\", xy=(0.98, 1.032), xytext=(0.505,1.032), xycoords=\"subfigure fraction\",  arrowprops=dict(facecolor='C1'))\n",
    "axs2[0][0].annotate(text=\"\", xy=(0.02, 1.032), xytext=(0.495,1.032), xycoords=\"subfigure fraction\",  arrowprops=dict(facecolor='C0'))\n",
    "axs2[0][0].annotate(text=\"Grade\", xy = (0.50,1.05), xycoords=\"subfigure fraction\", ha=\"center\", size = 18)\n",
    "axs2[0][0].annotate(text=\"Low\", xy = (0.02, 1.05), xycoords=\"subfigure fraction\", ha=\"center\", size = 16)\n",
    "axs2[0][0].annotate(text=\"High\", xy = (0.98, 1.05), xycoords=\"subfigure fraction\", ha=\"center\", size = 16)\n",
    "subfigs[0].text(-0.03,1.02,\"A\", zorder = 30, clip_on = False, weight='bold', size = 20 )\n",
    "subfigs[1].text(0.1,1.02,\"B\", zorder = 30, clip_on = False, weight='bold', size = 20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e9cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code loads the saved images for subtype transition, and also loads the results of models trained to predict subtype\n",
    "#to compare predictions for real slide images vs slide images regenerated with HistoXGAN\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open(PROJECT_DIR + '/FINAL_IMAGES/img_display_subtype_lr.pkl', 'rb') as f:\n",
    "    img_dict = pickle.load(f)\n",
    "    \n",
    "fig = plt.figure(figsize=(20, 8), dpi = 300)\n",
    "\n",
    "subfigs = fig.subfigures(1, 2, width_ratios=[14, 6])\n",
    "\n",
    "axs = subfigs[1].subplots(4, 2, sharex = True, sharey = True)\n",
    "\n",
    "result_table = []\n",
    "\n",
    "result_table += load_compare_group(\n",
    "    title = \"BRCA - TCGA\",\n",
    "    ax = axs[0][0],\n",
    "    class_names = [\"Ductal\", \"Lobular\"],\n",
    "    ylabel = \"BRCA\"\n",
    ")\n",
    "\n",
    "result_table += load_compare_group(\n",
    "    title = \"LUNG - TCGA\",\n",
    "    ax = axs[1][0],\n",
    "    class_names = [\"Adeno\", \"Squam\"],\n",
    "    ylabel = \"LUNG\"\n",
    ")\n",
    "\n",
    "result_table += load_compare_group(\n",
    "    title = \"ESCA - TCGA\",\n",
    "    ax = axs[2][0],\n",
    "    class_names = [\"Adeno\", \"Squam\"],\n",
    "    ylabel = \"ESCA\"\n",
    ")\n",
    "\n",
    "result_table += load_compare_group(\n",
    "    title = \"KIDNEY - TCGA\",\n",
    "    ax = axs[3][0],\n",
    "    ylabel = \"KIDNEY\",\n",
    "    class_names = [\"Clear\", \"Papillary\"],\n",
    "    xlabel = True\n",
    ")\n",
    "\n",
    "result_table += load_compare_group(\n",
    "    title = \"BRCA - CPTAC\",\n",
    "    ax = axs[0][1],\n",
    "    pred_df = True,\n",
    "    pred_class_col = \"histological_type\", \n",
    "    pred_class_opts = [\"Inflitrating Ductal Carcinoma\", \"Inflitrating Lobular Carcinoma\"],\n",
    "    class_names = [\"Ductal\", \"Lobular\"],\n",
    "    pred_only = True)\n",
    "\n",
    "result_table += load_compare_group(\n",
    "    title = \"LUNG - CPTAC\",\n",
    "    ax = axs[1][1],\n",
    "    pred_df = True,\n",
    "    pred_class_col = \"cohort\", \n",
    "    pred_class_opts = [\"LUAD\", \"LUSC\"],\n",
    "    class_names = [\"Adeno\", \"Squam\"],\n",
    "    pred_only = True,\n",
    "    xlabel = True\n",
    ")\n",
    "axs[3][1].set_visible(False)\n",
    "axs[2][1].set_visible(False)\n",
    "\n",
    "df = pd.DataFrame(result_table, columns = ['Dataset', 'Subtype', 'n', 'Histology A', 'Histology A (%)', 'Histology B', 'Histology B (%)', 'Pearson r', 'z statistic', 'p-value, correlation', 'AUROC', 'AP', 'AUROC Gen', 'AP Gen'])\n",
    "from IPython.display import display\n",
    "display(df)\n",
    "axs2 = subfigs[0].subplots(len(img_dict), img_include)\n",
    "\n",
    "row_loc = {\n",
    "    'BRCA':[20,30,40,50,60,70,80],\n",
    "    'LUNG':[20,30,40,50,60,70,80],\n",
    "    'ESCA':[20,30,40,50,60,70,80],\n",
    "    'KIDNEY':[0,15,30,50,70,85,99],\n",
    "}\n",
    "img_include = 7\n",
    "col = 0\n",
    "for img_name in img_dict:\n",
    "    row = 0\n",
    "    for row_item in row_loc[img_name]:\n",
    "        axs2[col][row].imshow(img_dict[img_name][row_item])\n",
    "        #axs[col][row].spines['right'].set_visible(False)\n",
    "        #axs[col][row].spines['top'].set_visible(False)\n",
    "        #axs[col][row].spines['left'].set_visible(False)\n",
    "        #axs[col][row].spines['bottom'].set_visible(False)\n",
    "        axs2[col][row].set_xticks([])\n",
    "        axs2[col][row].set_yticks([])\n",
    "        axs2[col][row].xaxis.set_label_position('top')\n",
    "        row = row + 1\n",
    "    str_name = img_name\n",
    "    axs2[col][0].set_ylabel(str_name, size = 18)\n",
    "    col = col + 1\n",
    "plt.tight_layout()\n",
    "subfigs[0].subplots_adjust(left = 0, top = 1, right = 1, bottom = 0, wspace=0, hspace=0)\n",
    "subfigs[1].subplots_adjust(left = 0.2, top = 1.0, bottom = 0, wspace = 0.1, hspace = 0.2)\n",
    "axs2[0][0].annotate(text=\"\", xy=(0.98, 1.032), xytext=(0.505,1.032), xycoords=\"subfigure fraction\",  arrowprops=dict(facecolor='C1'))\n",
    "axs2[0][0].annotate(text=\"\", xy=(0.02, 1.032), xytext=(0.495,1.032), xycoords=\"subfigure fraction\",  arrowprops=dict(facecolor='C0'))\n",
    "axs2[0][0].annotate(text=\"Subtype\", xy = (0.50,1.05), xycoords=\"subfigure fraction\", ha=\"center\", size = 18)\n",
    "padding = 3\n",
    "axs2[0][0].annotate(text=\"Ductal\", xy = (0.0, 1.0), xytext=(padding, -padding), xycoords=\"axes fraction\", textcoords='offset points', ha=\"left\", va = \"top\", size = 16,  bbox=dict(pad = padding, facecolor='white', edgecolor='black'))\n",
    "axs2[0][img_include - 1].annotate(text=\"Lobular\", xy = (1.0, 1.0), xytext=(-padding, -padding), xycoords=\"axes fraction\", textcoords='offset points', ha=\"right\", va = \"top\", size = 16,  bbox=dict(pad = padding, facecolor='white', edgecolor='black'))\n",
    "axs2[1][0].annotate(text=\"Adeno\", xy = (0.0, 1.0), xytext=(padding, -padding), xycoords=\"axes fraction\", textcoords='offset points', ha=\"left\", va = \"top\", size = 16,  bbox=dict(pad = padding, facecolor='white', edgecolor='black'))\n",
    "axs2[1][img_include - 1].annotate(text=\"Squamous\", xy = (1.0, 1.0), xytext=(-padding, -padding), xycoords=\"axes fraction\", textcoords='offset points', ha=\"right\", va = \"top\", size = 16,  bbox=dict(pad = padding, facecolor='white', edgecolor='black'))\n",
    "axs2[2][0].annotate(text=\"Adeno\", xy = (0.0, 1.0), xytext=(padding, -padding), xycoords=\"axes fraction\", textcoords='offset points', ha=\"left\", va = \"top\", size = 16,  bbox=dict(pad = padding, facecolor='white', edgecolor='black'))\n",
    "axs2[2][img_include - 1].annotate(text=\"Squamous\", xy = (1.0, 1.0), xytext=(-padding, -padding), xycoords=\"axes fraction\", textcoords='offset points', ha=\"right\", va = \"top\", size = 16,  bbox=dict(pad = padding, facecolor='white', edgecolor='black'))\n",
    "axs2[3][0].annotate(text=\"Clear\", xy = (0.0, 1.0), xytext=(padding, -padding), xycoords=\"axes fraction\", textcoords='offset points', ha=\"left\", va = \"top\", size = 16,  bbox=dict(pad = padding, facecolor='white', edgecolor='black'))\n",
    "axs2[3][img_include - 1].annotate(text=\"Papillary\", xy = (1.0, 1.0),xytext=(-padding, -padding), xycoords=\"axes fraction\", textcoords='offset points', ha=\"right\", va = \"top\", size = 16,  bbox=dict(pad = padding, facecolor='white', edgecolor='black'))\n",
    "\n",
    "subfigs[0].text(-0.03,1.02,\"A\", zorder = 30, clip_on = False, weight='bold', size = 20 )\n",
    "subfigs[1].text(0.1,1.02,\"B\", zorder = 30, clip_on = False, weight='bold', size = 20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc09556",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#The following code loads the saved images for gene transition, and also loads the results of models trained to predict gene expression\n",
    "#to compare predictions for real slide images vs slide images regenerated with HistoXGAN\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open(PROJECT_DIR + '/FINAL_IMAGES/img_display_gene_lr.pkl', 'rb') as f:\n",
    "    img_dict = pickle.load(f)\n",
    "    \n",
    "fig = plt.figure(figsize=(21, 8), dpi = 300)\n",
    "\n",
    "subfigs = fig.subfigures(1, 2, width_ratios=[14, 7])\n",
    "\n",
    "axs = subfigs[1].subplots(4, 2, sharex = True, sharey = True)\n",
    "\n",
    "result_table = []\n",
    "\n",
    "_, r = load_compare_group(\n",
    "    title = \"CD3G - TCGA\",\n",
    "    ax = axs[0][0],\n",
    "    class_names = [\"Low\", \"High\"],\n",
    "    color_df = True,\n",
    "    pred_class_col = \"CD3G\",\n",
    "    ylabel = \"CD3G\",\n",
    "    pred_only = True\n",
    ")\n",
    "result_table += r\n",
    "_, r = load_compare_group(\n",
    "    title = \"COL1A1 - TCGA\",\n",
    "    ax = axs[1][0],\n",
    "    class_names = [\"Low\", \"High\"],\n",
    "    ylabel = \"COL1A1\",\n",
    "    pred_class_col = \"COL1A1\",\n",
    "    color_df = True,\n",
    "    pred_only = True\n",
    ")\n",
    "result_table += r\n",
    "_, r = load_compare_group(\n",
    "    title = \"MKI67 - TCGA\",\n",
    "    ax = axs[2][0],\n",
    "    class_names = [\"Low\", \"High\"],\n",
    "    ylabel = \"MKI67\",\n",
    "    pred_class_col = \"MKI67\",\n",
    "    color_df = True,\n",
    "    pred_only = True\n",
    ")\n",
    "result_table += r\n",
    "_, r = load_compare_group(\n",
    "    title = \"EPCAM - TCGA\",\n",
    "    ax = axs[3][0],\n",
    "    ylabel = \"EPCAM\",\n",
    "    class_names = [\"Low\", \"High\"],\n",
    "    xlabel = True,\n",
    "    pred_class_col = \"EPCAM\",\n",
    "    color_df = True,\n",
    "    pred_only = True\n",
    ")\n",
    "\n",
    "result_table += r\n",
    "_, r = load_compare_group(\n",
    "    title = \"CD3G - CPTAC\",\n",
    "    ax = axs[0][1],\n",
    "    pred_class_col = \"CD3G\",\n",
    "    color_df = True,\n",
    "    pred_only = True,    \n",
    "    class_names = [\"Low\", \"High\"])\n",
    "\n",
    "\n",
    "result_table += r\n",
    "_, r = load_compare_group(\n",
    "    title = \"COL1A1 - CPTAC\",\n",
    "    ax = axs[1][1],\n",
    "    pred_class_col = \"COL1A1\",\n",
    "    color_df = True,\n",
    "    pred_only = True,\n",
    "    class_names = [\"Low\", \"High\"])\n",
    "\n",
    "\n",
    "result_table += r\n",
    "_, r = load_compare_group(\n",
    "    title = \"MKI67 - CPTAC\",\n",
    "    ax = axs[2][1],\n",
    "    pred_class_col = \"MKI67\",\n",
    "    color_df = True,\n",
    "    pred_only = True,\n",
    "    class_names = [\"Low\", \"High\"])\n",
    "\n",
    "\n",
    "result_table += r\n",
    "im, r = load_compare_group(\n",
    "    title = \"EPCAM - CPTAC\",\n",
    "    ax = axs[3][1],\n",
    "    pred_class_col = \"EPCAM\",\n",
    "    xlabel = True,\n",
    "    color_df = True,\n",
    "    pred_only = True,\n",
    "    class_names = [\"Low\", \"High\"])\n",
    "result_table += r\n",
    "\n",
    "axs2 = subfigs[0].subplots(len(img_dict), img_include)\n",
    "\n",
    "row_loc = {\n",
    "    'CD3G':[20,30,40,50,60,70,80],\n",
    "    'COL1A1':[20,30,40,50,60,70,80],\n",
    "    'MKI67':[20,30,40,50,60,70,80],\n",
    "    'EPCAM':[20,30,40,50,60,70,80],\n",
    "}\n",
    "img_include = 7\n",
    "col = 0\n",
    "for img_name in img_dict:\n",
    "    row = 0\n",
    "    for row_item in row_loc[img_name]:\n",
    "        axs2[col][row].imshow(img_dict[img_name][row_item])\n",
    "        #axs[col][row].spines['right'].set_visible(False)\n",
    "        #axs[col][row].spines['top'].set_visible(False)\n",
    "        #axs[col][row].spines['left'].set_visible(False)\n",
    "        #axs[col][row].spines['bottom'].set_visible(False)\n",
    "        axs2[col][row].set_xticks([])\n",
    "        axs2[col][row].set_yticks([])\n",
    "        axs2[col][row].xaxis.set_label_position('top')\n",
    "        row = row + 1\n",
    "    str_name = img_name\n",
    "    axs2[col][0].set_ylabel(str_name, size = 18)\n",
    "    col = col + 1\n",
    "plt.tight_layout()\n",
    "\n",
    "subfigs[1].subplots_adjust(left = 0.15, top = 1.0, bottom = 0, wspace = 0.07, hspace = 0.2)\n",
    "subfigs[1].colorbar(im, ax=axs.ravel().tolist(), location = 'right', orientation = 'vertical', pad = 0.02, fraction = 0.07, aspect = 60, anchor = (0,0))\n",
    "\n",
    "subfigs[0].subplots_adjust(left = 0, top = 1, right = 1, bottom = 0, wspace=0, hspace=0)\n",
    "\n",
    "axs2[0][0].annotate(text=\"\", xy=(0.98, 1.032), xytext=(0.505,1.032), xycoords=\"subfigure fraction\",  arrowprops=dict(facecolor='C1'))\n",
    "axs2[0][0].annotate(text=\"\", xy=(0.02, 1.032), xytext=(0.495,1.032), xycoords=\"subfigure fraction\",  arrowprops=dict(facecolor='C0'))\n",
    "axs2[0][0].annotate(text=\"Gene\", xy = (0.50,1.05), xycoords=\"subfigure fraction\", ha=\"center\", size = 18)\n",
    "axs2[0][0].annotate(text=\"Low\", xy = (0.02, 1.05), xycoords=\"subfigure fraction\", ha=\"center\", size = 16)\n",
    "axs2[0][0].annotate(text=\"High\", xy = (0.98, 1.05), xycoords=\"subfigure fraction\", ha=\"center\", size = 16)\n",
    "\n",
    "\n",
    "subfigs[0].text(-0.03,1.02,\"A\", zorder = 30, clip_on = False, weight='bold', size = 20 )\n",
    "subfigs[1].text(0.1,1.02,\"B\", zorder = 30, clip_on = False, weight='bold', size = 20)\n",
    "\n",
    "df = pd.DataFrame(result_table, columns = ['Dataset', 'Subtype', 'n', 'Histology A', 'Histology A (%)', 'Histology B', 'Histology B (%)', 'Pearson r', 'z statistic', 'p-value, correlation', 'AUROC', 'AP', 'AUROC Gen', 'AP Gen'])\n",
    "df = df.drop(columns = ['Histology A', 'Histology A (%)', 'Histology B', 'Histology B (%)'])\n",
    "from IPython.display import display\n",
    "display(df)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8767b8e",
   "metadata": {},
   "source": [
    "\n",
    "# Loss Based Feature Vector PCA + Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9635fe6",
   "metadata": {},
   "source": [
    "## This code explores using model loss (rather than average difference in feature vector) to explore how predictions are made. Gradient descent is used to calculate how to make images score higher / lower for a deep learning model. This is repeated 50 times to generate a list of gradients, and PCA is performed to identify principle compoennts of these gradients, representing different directions in the feature space that are important to model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080692d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slideflow.model.torch import load as load_torch_model\n",
    "\n",
    "from slideflow.gan.stylegan3.stylegan3 import dnnlib, legacy, utils\n",
    "with dnnlib.util.open_url(PROJECT_DIR + '/FINAL_MODELS/CTransPath/snapshot.pkl') as f:\n",
    "    G = legacy.load_network_pkl(f)['G_ema'].to(device)\n",
    "\n",
    "def vector_interpolate(\n",
    "    G: torch.nn.Module,\n",
    "    z: torch.tensor,\n",
    "    z2: torch.tensor,\n",
    "    device: torch.device,\n",
    "    steps: int = 100\n",
    "):\n",
    "    for interp_idx in range(steps):\n",
    "        torch_interp = torch.tensor(z - z2 + 2*interp_idx/steps*z2).to(device)\n",
    "        img = G(torch_interp, 0, noise_mode ='const')\n",
    "        img = (img + 1) * (255/2)\n",
    "        img = img.permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
    "        yield img\n",
    "\n",
    "def generate_images(vector_z, vector_z2, prefix = 'test'):\n",
    "    z = torch.tensor(vector_z).to(device)\n",
    "    z2 = torch.tensor(vector_z2).to(device)\n",
    "    img_array = []\n",
    "    generator = vector_interpolate(G, z, z2, device = device)\n",
    "    for interp_idx, img in enumerate(generator):\n",
    "        img_array += [img]\n",
    "    return img_array\n",
    "\n",
    "def lighten_color(color, amount=1.5):\n",
    "    \"\"\"\n",
    "    Lightens the given color by multiplying (1-luminosity) by the given amount.\n",
    "    Input can be matplotlib color string, hex string, or RGB tuple.\n",
    "\n",
    "    Examples:\n",
    "    >> lighten_color('g', 0.3)\n",
    "    >> lighten_color('#F034A3', 0.6)\n",
    "    >> lighten_color((.3,.55,.1), 0.5)\n",
    "    \"\"\"\n",
    "    import matplotlib.colors as mc\n",
    "    import colorsys\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
    "    return colorsys.hls_to_rgb(c[0], 1 - amount * (1 - c[1]), c[2])\n",
    "\n",
    "def get_pca_vectors(df_mod, entries, feat_cols, mod, dataset, vectors_dict, a, b, ax):\n",
    "    from sklearn.decomposition import PCA\n",
    "    n_comp = 20\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    \n",
    "    result = pca.fit_transform(vectors_dict['loss'])\n",
    "    plot_pts = pca.transform(vectors_dict['base'])\n",
    "    \n",
    "    full_data = pca.transform(df_mod[feat_cols].values.tolist())\n",
    "    \n",
    "    tick = 0.05\n",
    "    x_list, y_list = np.meshgrid(np.arange(-4, 4.01, tick), np.arange(-4, 4.01, tick))\n",
    "    important_pca = [x for x in range(n_comp)]\n",
    "    \n",
    "    for i in range(n_comp):\n",
    "        for j in range(n_comp):\n",
    "            pca_1 = important_pca[i]\n",
    "            pca_2 = important_pca[j]\n",
    "            if np.abs(np.mean([result[x][pca_2] for x in range(entries)])) < np.abs(np.mean([result[x][pca_1] for x in range(entries)])):\n",
    "                important_pca[i] = pca_2\n",
    "                important_pca[j] = pca_1\n",
    "\n",
    "    A = np.array(full_data)[:entries, [important_pca[a], important_pca[b]]]\n",
    "    x = 0\n",
    "    y = 0\n",
    "\n",
    "    x_final = []\n",
    "    y_final = []\n",
    "    base_final = []\n",
    "    loss_final = []\n",
    "    slide_final = []\n",
    "    grade_pred = []\n",
    "    count_min = []\n",
    "    \n",
    "    model = load_torch_model(mod).eval().to(device)\n",
    "    preprocess = sf.util.get_preprocess_fn(mod)\n",
    "    loss_fn = torch.nn.L1Loss().to(device)\n",
    "    softmax = torch.nn.Softmax(dim = -1)    \n",
    "    \n",
    "    verbose = False\n",
    "    distances = np.linalg.norm(A - np.array((0,0)), axis=1)\n",
    "    min_index = np.argmin(distances)\n",
    "    \n",
    "    min_dist = math.sqrt((tick/2) * (tick/2) + (tick/2)*(tick/2))\n",
    "    for x_r, y_r in zip(x_list, y_list):\n",
    "        for x, y in zip(x_r, y_r):\n",
    "            distances = np.linalg.norm(A - np.array((x,y)), axis=1)\n",
    "            min_index = np.argmin(distances)\n",
    "            \n",
    "            if distances[min_index] < min_dist:\n",
    "                count_min += [(distances < 0.1).sum()]\n",
    "                vector_patient = df_mod['Slide'].loc[min_index][0:12]\n",
    "                grade_pred += [vectors_dict['pred'][min_index]]\n",
    "                x_final += [x]\n",
    "                y_final += [y]\n",
    "                base_final += [vectors_dict['base'][min_index]]\n",
    "                loss_final += [vectors_dict['loss'][min_index]]\n",
    "                if verbose:\n",
    "                    print(vector_patient)\n",
    "                    print(vector_grade)\n",
    "                    print(x)\n",
    "                    print(y)\n",
    "                    print(min_index)\n",
    "                    print(A[min_index])\n",
    "                    print(distances[min_index])\n",
    "                    print()\n",
    "\n",
    "    base_pca = pca.transform(base_final)\n",
    "    loss_pca = np.array(pca.transform(loss_final))\n",
    "\n",
    "    from sklearn.preprocessing import normalize\n",
    "    loss_pca_norm = normalize(loss_pca[:, [important_pca[a], important_pca[b]]])\n",
    "    \n",
    "    from sklearn.preprocessing import QuantileTransformer\n",
    "    qt = QuantileTransformer(n_quantiles=100, random_state=0)\n",
    "    import matplotlib\n",
    "    cmap = matplotlib.cm.get_cmap('Blues')\n",
    "\n",
    "    for x, y, l1, l2, g, lw in zip(x_final, y_final, loss_pca_norm[:, 0], loss_pca_norm[:, 1], grade_pred, qt.fit_transform(np.linalg.norm(loss_pca[:, [important_pca[a], important_pca[b]]], axis = 1).reshape(-1,1))):\n",
    "        ax.quiver(x, y, l1, l2, color = cmap(g/2 + 0.25), scale = 35, width = lw/200 + 0.005, headwidth = 3, headlength = 1.5, headaxislength = 1.5)#, width = lw/400 + 0.002, headlength = 10*lw)\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    max_a = np.argmax(loss_pca[:, important_pca[a]])\n",
    "    max_b = np.argmax(loss_pca[:, important_pca[b]])\n",
    "    if max_b == max_a:\n",
    "        max_b = np.argsort(loss_pca[:, important_pca[b]])[-2]\n",
    "    str_list = [\"Max Gradient PC 1\", \"Max Gradient PC 2\", \"Max Gradient PC 3\", \"Max Gradient PC 4\"]\n",
    "    cmap = matplotlib.cm.get_cmap('Reds')\n",
    "    qt_res = qt.fit_transform(np.linalg.norm(loss_pca[:, [important_pca[a], important_pca[b]]], axis = 1).reshape(-1,1))\n",
    "    ax.quiver(x_final[max_a], y_final[max_a], loss_pca_norm[max_a, 0], loss_pca_norm[max_a, 1], color = 'C1', scale = 35, width = qt_res[max_a][0]/200 + 0.005, headwidth = 3, headlength = 1.5, headaxislength = 1.5, label = str_list[a])#, width = lw/400 + 0.002, headlength = 10*lw)\n",
    "    ax.quiver(x_final[max_b], y_final[max_b], loss_pca_norm[max_b, 0], loss_pca_norm[max_b, 1], color = lighten_color('C1'), scale = 35, width = qt_res[max_b][0]/200 + 0.005, headwidth = 3, headlength = 1.5, headaxislength = 1.5, label = str_list[b])\n",
    "    ax.legend()\n",
    "    return df_mod[feat_cols].loc[max_a, :].values.tolist(), df_mod[feat_cols].loc[max_b, :].values.tolist()\n",
    "\n",
    "\n",
    "def load_models(mod, patient = 200, entries = 50, full_set = False, regen = False, dataset = 'BRCA', fig_overall = None, label = {}, race = False):\n",
    "    \n",
    "    #Get the dataset\n",
    "    from random import randrange\n",
    "    from tqdm import tqdm\n",
    "    if full_set:\n",
    "        df_mod = pd.read_csv(PROJECT_DIR + '/PROJECTS/HistoXGAN/SAVED_FEATURES/' + dataset.lower() + '_features_slide.csv') \n",
    "        entries = len(df_mod.index)\n",
    "    else:\n",
    "        #Not implemented for public release given need for full extracted features from slides (~4 GB per dataset)\n",
    "        raise NotImplementedError(\"Requires full set of extracted features - not implemented\")\n",
    "\n",
    "    feat_cols = list(df_mod.columns.values)\n",
    "    feat_cols = [f for f in feat_cols if 'Feature_' in f]      \n",
    "    print(\"Rows imported\")\n",
    "    # Load the slideflow model\n",
    "    model = load_torch_model(mod).eval().to(device)\n",
    "    preprocess = sf.util.get_preprocess_fn(mod)\n",
    "    loss_fn = torch.nn.L1Loss().to(device)\n",
    "    softmax = torch.nn.Softmax(dim = -1)    \n",
    "    vectors_dict = {}\n",
    "    vectors_dict['loss'] = []\n",
    "    vectors_dict['base'] = []\n",
    "    vectors_dict['slide'] = []\n",
    "    vectors_dict['pred'] = []\n",
    "    import os.path\n",
    "    if not full_set:\n",
    "        if not regen and os.path.isfile(os.path.dirname(mod) + \"/\" + str(entries) + \"_vectors_dict_pca_nav.pkl\"):\n",
    "            with open(os.path.dirname(mod) + \"/\" + str(entries) + \"_vectors_dict_pca_nav.pkl\", 'rb') as f:\n",
    "                vectors_dict = pickle.load(f)\n",
    "        else:\n",
    "            for tensor_vector_target in [1,0]:\n",
    "                for i in tqdm(range(entries)):\n",
    "                    r = i\n",
    "                    vector_base = df_mod[feat_cols].loc[r, :].values.tolist()\n",
    "                    vectors_dict['base'] += [vector_base]\n",
    "                    vectors_dict['slide'] += df_mod['Slide'].loc[r]\n",
    "                    vector_base_tensor = torch.tensor([vector_base]).to(device)\n",
    "                    vector_base_tensor.requires_grad = True\n",
    "                    optimizer = torch.optim.SGD([vector_base_tensor], lr=1e-3)\n",
    "                    pred = softmax(model(G(vector_base_tensor, 0, noise_mode ='const')))\n",
    "                    loss = loss_fn(pred[0][1], torch.tensor(tensor_vector_target).to(device))\n",
    "                    vectors_dict['pred'] += [pred[0][1].detach().cpu().numpy()]\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    vectors_dict['loss'] += [-1 * vector_base_tensor.grad.detach().cpu().numpy()[0]]\n",
    "            with open(os.path.dirname(mod) + \"/\" + str(entries) + \"_vectors_dict_pca_nav.pkl\", 'wb') as f:\n",
    "                pickle.dump(vectors_dict, f)\n",
    "    else:\n",
    "        entires = len(df_mod.index)\n",
    "        if not regen and os.path.isfile(os.path.dirname(mod)  + \"/\" +  \"fullset_vectors_dict_pca_nav.pkl\"):\n",
    "            with open(os.path.dirname(mod)  + \"/\" +  \"fullset_vectors_dict_pca_nav.pkl\", 'rb') as f:\n",
    "                vectors_dict = pickle.load(f)\n",
    "        else:\n",
    "            for tensor_vector_target in [1,0]:\n",
    "                for i in tqdm(range(len(df_mod.index))):\n",
    "                    vector_base = df_mod[feat_cols].loc[i, :].values.tolist()\n",
    "                    vectors_dict['base'] += [vector_base]\n",
    "                    vectors_dict['slide'] += df_mod['Slide'].loc[i]\n",
    "                    vector_base_tensor = torch.tensor([vector_base]).to(device)\n",
    "                    vector_base_tensor.requires_grad = True\n",
    "                    optimizer = torch.optim.SGD([vector_base_tensor], lr=1e-3)\n",
    "                    pred = softmax(model(G(vector_base_tensor, 0, noise_mode ='const')))\n",
    "                    loss = loss_fn(pred[0][1], torch.tensor(tensor_vector_target).to(device))\n",
    "                    vectors_dict['pred'] += [pred[0][1].detach().cpu().numpy()]\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    vectors_dict['loss'] += [-1 * vector_base_tensor.grad.detach().cpu().numpy()[0]]\n",
    "            with open(os.path.dirname(mod)  + \"/\" +  \"fullset_vectors_dict_pca_nav.pkl\", 'wb') as f:\n",
    "                pickle.dump(vectors_dict, f)\n",
    "\n",
    "    #df_plot = pd.DataFrame(data = [plot_slides, plot_vectors, loss_vectors], columns = ['Slide', 'Vector', 'Loss'])\n",
    "    \n",
    "    from sklearn.decomposition import PCA\n",
    "    n_comp = 20\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    #result_base = pca.fit_transform(vectors_dict['base'])\n",
    "    \n",
    "    #result = pca.transform(vectors_dict['loss'])\n",
    "    \n",
    "    result = pca.fit_transform(vectors_dict['loss'])\n",
    "    subfigs = fig_overall.subfigures(1,3, width_ratios = [6, 20, 3])\n",
    "\n",
    "    axs1 = subfigs[0].subplots(2, 1)\n",
    "\n",
    "    patient_vectors = []\n",
    "    a, b = get_pca_vectors(df_mod, entries, feat_cols, mod, dataset, vectors_dict, 0, 1, axs1[0])\n",
    "    c, d = get_pca_vectors(df_mod, entries, feat_cols, mod, dataset, vectors_dict, 2, 3, axs1[1])\n",
    "    patient_vectors = [a,b,c,d]\n",
    "    axs1[0].set_xlabel('PC 1')\n",
    "    axs1[0].set_ylabel('PC 2')\n",
    "    axs1[1].set_xlabel('PC 3')\n",
    "    axs1[1].set_ylabel('PC 4')\n",
    "    \n",
    "    img_dict = {}\n",
    "    row_loc = {}\n",
    "    important_pca = [x for x in range(n_comp)]\n",
    "    for i in range(n_comp):\n",
    "        for j in range(n_comp):\n",
    "            pca_1 = important_pca[i]\n",
    "            pca_2 = important_pca[j]\n",
    "            if np.abs(np.mean([result[x][pca_2] for x in range(entries)])) < np.abs(np.mean([result[x][pca_1] for x in range(entries)])):\n",
    "                important_pca[i] = pca_2\n",
    "                important_pca[j] = pca_1\n",
    "    if not regen and os.path.isfile(os.path.dirname(mod)  + \"/\" +  \"img_dict_pca_nav.pkl\"):\n",
    "        with open(os.path.dirname(mod)  + \"/\" +  \"img_dict_pca_nav.pkl\", 'rb') as f:\n",
    "            img_dict = pickle.load(f)\n",
    "    else:\n",
    "        for i in range(4):\n",
    "            img_dict[str(i)] = generate_images([patient_vectors[i]], [pca.components_[important_pca[i]]])\n",
    "            if np.mean([result[x][important_pca[i]] for x in range(entries)]) > 0:\n",
    "                row_loc[str(i)] = [15,30,40,50,60,70,85]\n",
    "            else:\n",
    "                row_loc[str(i)] = [85, 70, 60, 50, 40, 30, 15]\n",
    "            grades = []\n",
    "            for rs in row_loc[str(i)]:\n",
    "                z = torch.tensor([patient_vectors[i]])\n",
    "                z2 = torch.tensor([pca.components_[important_pca[i]]])\n",
    "                torch_interp = torch.tensor(z - z2 + 2*rs/100*z2).to(device)\n",
    "                img = G(torch_interp, 0, noise_mode ='const')\n",
    "                m = model(img)\n",
    "                grades += [softmax(m)[0].detach().cpu().numpy()[1]]\n",
    "            print(grades)\n",
    "        with open(os.path.dirname(mod)  + \"/\" +  \"img_dict_pca_nav.pkl\", 'wb') as f:\n",
    "            pickle.dump(img_dict, f)\n",
    "    for i in range(4):\n",
    "        if np.mean([result[x][important_pca[i]] for x in range(entries)]) > 0:\n",
    "            row_loc[str(i)] = [15,30,40,50,60,70,85]\n",
    "        else:\n",
    "            row_loc[str(i)] = [85, 70, 60, 50, 40, 30, 15]\n",
    "    img_include = 7 \n",
    "    rows = len(img_dict)\n",
    "    #gs = plt.GridSpec(ncols = img_include, nrows = rows, left = 0, top = 1, right = 1, bottom = 0, wspace=0, hspace=0)\n",
    "    #gs_final = plt.GridSpec(ncols = img_include, nrows = rows, left = 0, top = 1, right = 1, bottom = 0, wspace=0, hspace=0)\n",
    "    #, axes = plt.subplots(rows, img_include, figsize = (2*img_include,2*rows))\n",
    "    axs = subfigs[1].subplots(len(img_dict), img_include)\n",
    "\n",
    "    imp_total = 0\n",
    "    for col in range(20):\n",
    "        imp_total += np.abs(np.mean([result[x][important_pca[col]] for x in range(entries)]) - np.mean([result[entries + x][important_pca[col]] for x in range(entries)]))\n",
    "        \n",
    "    col = 0\n",
    "    axs2 = subfigs[2].subplots(len(img_dict), 1)\n",
    "    \n",
    "    res_dict = []\n",
    "    for img_name in img_dict:\n",
    "        row = 0\n",
    "        for row_item in row_loc[img_name]:   \n",
    "            axs[col][row].imshow(img_dict[img_name][row_item])\n",
    "            #axs[col][row].spines['right'].set_visible(False)\n",
    "            #axs[col][row].spines['top'].set_visible(False)\n",
    "            #axs[col][row].spines['left'].set_visible(False)\n",
    "            #axs[col][row].spines['bottom'].set_visible(False)\n",
    "            axs[col][row].set_xticks([])\n",
    "            axs[col][row].set_yticks([])\n",
    "            axs[col][row].xaxis.set_label_position('top')\n",
    "            row = row + 1\n",
    "        str_trans = {'0':'PC 1', '1':'PC 2', '2':'PC 3', '3':'PC 4'}\n",
    "        str_name = img_name\n",
    "        axs[col][0].set_ylabel(str_trans[str_name], size = 18)\n",
    "\n",
    "        axs2[col].barh([1 - 0.2], [np.abs(np.mean([result[x][important_pca[col]] for x in range(entries)]) - np.mean([result[entries + x][important_pca[col]] for x in range(entries)])) / imp_total], height = 0.8, label = \"Contribution to Prediction\")\n",
    "        axs2[col].barh([0 - 0.2], [pca.explained_variance_ratio_[important_pca[col]]], height = 0.8, label = \"Variance Explained\")\n",
    "\n",
    "        res_dict_col = [dataset, label[0], entries]\n",
    "        \n",
    "        res_dict_col += [np.abs(np.mean([result[x][important_pca[col]] for x in range(entries)]) - np.mean([result[entries + x][important_pca[col]] for x in range(entries)])) / imp_total]\n",
    "        res_dict_col += [np.sqrt(np.square(np.std([result[x][important_pca[col]] for x in range(entries)])) + np.square(np.std([result[entries + x][important_pca[col]] for x in range(entries)]))) / imp_total]\n",
    "        res_dict_col += [pca.explained_variance_ratio_[important_pca[col]]]\n",
    "        if col == 0:\n",
    "            res_dict += [res_dict_col]\n",
    "        axs2[col].spines['right'].set_visible(False)\n",
    "        axs2[col].spines['top'].set_visible(False)\n",
    "        #axs[col][row].spines['left'].set_visible(False)\n",
    "        axs2[col].set_yticks([])\n",
    "        axs2[col].axes.get_yaxis().set_visible(False)\n",
    "        axs2[col].set_ylim([-1,2])\n",
    "        axs2[col].set_xlim([0, 1])\n",
    "        if col != rows - 1:\n",
    "            axs2[col].axes.get_xaxis().set_visible(False)\n",
    "            axs2[col].spines['bottom'].set_visible(False)\n",
    "        if col == 0:\n",
    "            axs2[col].legend(bbox_to_anchor=(0.04, 0.7))\n",
    "        col = col + 1\n",
    "    plt.tight_layout()\n",
    "    subfigs[1].subplots_adjust(left = 0, top = 1, right = 1, bottom = 0.1, wspace=0, hspace=0)\n",
    "    subfigs[2].subplots_adjust(left = 0, top = 1, right = 1, bottom = 0.1, wspace=0, hspace=0)\n",
    "    subfigs[0].subplots_adjust(left = 0, top = 1, right = 0.85, bottom = 0.1, wspace=0, hspace =0.1)\n",
    "    axs[0][0].annotate(text=\"\", xy=(0.98, 1.032), xytext=(0.505,1.032), xycoords=\"subfigure fraction\",  arrowprops=dict(facecolor='C1'))\n",
    "    axs[0][0].annotate(text=\"\", xy=(0.02, 1.032), xytext=(0.495,1.032), xycoords=\"subfigure fraction\",  arrowprops=dict(facecolor='C0'))\n",
    "    axs[0][0].annotate(text=label[0], xy = (0.50,1.05), xycoords=\"subfigure fraction\", ha=\"center\", size = 18)\n",
    "    axs[0][0].annotate(text=label[1], xy = (0.02, 1.05), xycoords=\"subfigure fraction\", ha=\"center\", size = 16)\n",
    "    axs[0][0].annotate(text=label[2], xy = (0.98, 1.05), xycoords=\"subfigure fraction\", ha=\"center\", size = 16)\n",
    "    \n",
    "    subfigs[0].text(-0.03,1.02,label[3], zorder = 30, clip_on = False, weight='bold', size = 20 )\n",
    "    subfigs[1].text(-0.03,1.02,label[4], zorder = 30, clip_on = False, weight='bold', size = 20)\n",
    "    subfigs[2].text(0.1,1.02,label[5], zorder = 30, clip_on = False, weight='bold', size = 20)\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a455ad",
   "metadata": {},
   "source": [
    "## Loss based PCA feature space exploration comparison for grade and tissue source site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aedb6bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_overall = plt.figure(figsize=(18, 16), dpi = 300)\n",
    "subfigs = fig_overall.subfigures(2, 1)\n",
    "res_dict = []\n",
    "res_dict = load_models(PROJECT_DIR + '/PRETRAINED_MODELS/BRCA_GRADE/high_grade.zip', entries = 500, full_set = True, regen = False, fig_overall = subfigs[0], label = ['Grade', 'Low', 'High', 'A', 'B', 'C'])\n",
    "res_dict += load_models(PROJECT_DIR + '/PRETRAINED_MODELS/BRCA_SITE/SITE-HP0_epoch3.zip', entries = 500, full_set = True, regen = False, fig_overall = subfigs[1], label = ['Site', '', '', 'D', 'E', 'F'])\n",
    "\n",
    "df_res = pd.DataFrame(res_dict, columns = ['Cancer', 'Outcome', 'n', 'Contribution', 'stdev', 'Variance'])\n",
    "df_res['Contribution'] = df_res['Contribution'].map(lambda x: '{:.3f}'.format(x)) + \" (\" + df_res['stdev'].map(lambda x: '{:.3f}'.format(x)) + \") \"\n",
    "df_res['Variance'] = df_res['Variance'].map(lambda x: '{:.3f}'.format(x))\n",
    "df_res.drop(columns = ['stdev'], inplace = True)\n",
    "from IPython.display import display\n",
    "display(df_res)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618add46",
   "metadata": {},
   "source": [
    "## The following is used to perform gradient descent to identify principle components for site, ancestry, and after normalization for site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de6463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models_site(mod, patient = 200, entries = 50, full_set = False, regen = False, dataset = 'BRCA', fig_overall = None, label = {}, fixed_patient = False, fixed_patient_values = None):\n",
    "    \n",
    "    #Get the dataset\n",
    "    \n",
    "    from random import randrange\n",
    "    from tqdm import tqdm\n",
    "    if full_set:\n",
    "        df_mod = pd.read_csv(PROJECT_DIR + '/PROJECTS/HistoXGAN/SAVED_FEATURES/' + dataset.lower() + '_features_slide.csv') \n",
    "        entries = len(df_mod.index)\n",
    "    else:\n",
    "        #Not implemented for public release given need for full extracted features from slides (~4 GB per dataset)\n",
    "        raise NotImplementedError(\"Requires full set of extracted features - not implemented\")\n",
    "\n",
    "    feat_cols = list(df_mod.columns.values)\n",
    "    feat_cols = [f for f in feat_cols if 'Feature_' in f]      \n",
    "    print(\"Rows imported\")\n",
    "    # Load the slideflow model\n",
    "    model = load_torch_model(mod).eval().to(device)\n",
    "    preprocess = sf.util.get_preprocess_fn(mod)\n",
    "    loss_fn = torch.nn.L1Loss().to(device)\n",
    "    softmax = torch.nn.Softmax(dim = -1)    \n",
    "    vectors_dict = {}\n",
    "    vectors_dict['loss'] = []\n",
    "    vectors_dict['base'] = []\n",
    "    vectors_dict['slide'] = []\n",
    "    vectors_dict['pred'] = []\n",
    "    import os.path\n",
    "    if not full_set:\n",
    "        if not regen and os.path.isfile(os.path.dirname(mod)  + \"/\" +  str(entries) + \"_vectors_dict.pkl\"):\n",
    "            with open(os.path.dirname(mod)  + \"/\" +  str(entries) + \"_vectors_dict.pkl\", 'rb') as f:\n",
    "                vectors_dict = pickle.load(f)\n",
    "        else:\n",
    "            for tensor_vector_target in [1,0]:\n",
    "                for i in tqdm(range(entries)):\n",
    "                    r = i\n",
    "                    vector_base = df_mod[feat_cols].loc[r, :].values.tolist()\n",
    "                    vectors_dict['base'] += [vector_base]\n",
    "                    vectors_dict['slide'] += df_mod['Slide'].loc[r]\n",
    "                    vector_base_tensor = torch.tensor([vector_base]).to(device)\n",
    "                    vector_base_tensor.requires_grad = True\n",
    "                    optimizer = torch.optim.SGD([vector_base_tensor], lr=1e-3)\n",
    "                    pred = softmax(model(G(vector_base_tensor, 0, noise_mode ='const')))\n",
    "                    loss = loss_fn(pred[0][1], torch.tensor(tensor_vector_target).to(device))\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    vectors_dict['loss'] += [-1 * vector_base_tensor.grad.detach().cpu().numpy()[0]]\n",
    "            with open(os.path.dirname(mod)  + \"/\" +  str(entries) + \"_vectors_dict.pkl\", 'wb') as f:\n",
    "                pickle.dump(vectors_dict, f)\n",
    "    else:\n",
    "        entires = len(df_mod.index)\n",
    "        if not regen and os.path.isfile(os.path.dirname(mod)  + \"/\" +  \"fullset_vectors_dict.pkl\"):\n",
    "            with open(os.path.dirname(mod)  + \"/\" +  \"fullset_vectors_dict.pkl\", 'rb') as f:\n",
    "                vectors_dict = pickle.load(f)\n",
    "        else:\n",
    "            for tensor_vector_target in [1,0]:\n",
    "                for i in tqdm(range(len(df_mod.index))):\n",
    "                    vector_base = df_mod[feat_cols].loc[i, :].values.tolist()\n",
    "                    vectors_dict['base'] += [vector_base]\n",
    "                    vectors_dict['slide'] += df_mod['Slide'].loc[i]\n",
    "                    vector_base_tensor = torch.tensor([vector_base]).to(device)\n",
    "                    vector_base_tensor.requires_grad = True\n",
    "                    optimizer = torch.optim.SGD([vector_base_tensor], lr=1e-3)\n",
    "                    pred = softmax(model(G(vector_base_tensor, 0, noise_mode ='const')))\n",
    "                    loss = loss_fn(pred[0][1], torch.tensor(tensor_vector_target).to(device))\n",
    "                    vectors_dict['pred'] += [pred[0][1].detach().cpu().numpy()]\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    vectors_dict['loss'] += [-1 * vector_base_tensor.grad.detach().cpu().numpy()[0]]\n",
    "            with open(os.path.dirname(mod)  + \"/\" +  \"fullset_vectors_dict.pkl\", 'wb') as f:\n",
    "                pickle.dump(vectors_dict, f)\n",
    "\n",
    "    #df_plot = pd.DataFrame(data = [plot_slides, plot_vectors, loss_vectors], columns = ['Slide', 'Vector', 'Loss'])\n",
    "    \n",
    "    from sklearn.decomposition import PCA\n",
    "    n_comp = 20\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    #result_base = pca.fit_transform(vectors_dict['base'])\n",
    "    \n",
    "    #result = pca.transform(vectors_dict['loss'])\n",
    "    \n",
    "    result = pca.fit_transform(vectors_dict['loss'])\n",
    "    \n",
    "    important_pca = [x for x in range(n_comp)]\n",
    "    for i in range(n_comp):\n",
    "        for j in range(n_comp):\n",
    "            pca_1 = important_pca[i]\n",
    "            pca_2 = important_pca[j]\n",
    "            if np.abs(np.mean([result[x][pca_2] for x in range(entries)])) < np.abs(np.mean([result[x][pca_1] for x in range(entries)])):\n",
    "                important_pca[i] = pca_2\n",
    "                important_pca[j] = pca_1\n",
    "                \n",
    "    if fixed_patient:\n",
    "        import numbers\n",
    "        if fixed_patient_values:\n",
    "            patient_vectors = {}\n",
    "            patient_vectors[0] = vectors_dict['base'][fixed_patient_values]\n",
    "            with open(PROJECT_DIR + \"/pub_pkl/patient_vector_site_\" +dataset + \".pkl\", 'wb') as f:\n",
    "                pickle.dump(patient_vectors, f)           \n",
    "            #print(patient_vectors)\n",
    "        if os.path.isfile(PROJECT_DIR + \"/pub_pkl/patient_vector_site_\" +dataset + \".pkl\"):\n",
    "            with open(PROJECT_DIR + \"/pub_pkl/patient_vector_site_\" +dataset + \".pkl\", 'rb') as f:\n",
    "                patient_vectors = pickle.load(f)\n",
    "        #print(patient_vectors)\n",
    "    else:\n",
    "        patient_vectors = []\n",
    "        print(np.argmax(result[:entries, important_pca[0]]))\n",
    "        a = vectors_dict['base'][np.argmax(result[:entries, important_pca[0]])]\n",
    "        b = vectors_dict['base'][np.argmax(result[:entries, important_pca[1]])]\n",
    "        c = vectors_dict['base'][np.argmax(result[:entries, important_pca[2]])]\n",
    "        d = vectors_dict['base'][np.argmax(result[:entries, important_pca[3]])]\n",
    "        patient_vectors = [a,b,c,d]  \n",
    "    img_dict = {}\n",
    "    row_loc = {}\n",
    "\n",
    "    img_dict = generate_images([patient_vectors[0]], [pca.components_[important_pca[0]]])\n",
    "    imp_total = 0\n",
    "    for col in range(20):\n",
    "        imp_total += np.abs(np.mean([result[x][important_pca[col]] for x in range(entries)]) - np.mean([result[entries + x][important_pca[col]] for x in range(entries)]))\n",
    "        #print(imp_total)\n",
    "    contrib = np.abs(np.mean([result[x][important_pca[0]] for x in range(entries)]) - np.mean([result[entries + x][important_pca[0]] for x in range(entries)])) / imp_total\n",
    "    var_ratio = pca.explained_variance_ratio_[important_pca[0]]\n",
    "    if np.mean([result[x][important_pca[i]] for x in range(entries)]) > np.mean([result[x + entries][important_pca[i]] for x in range(entries)]):\n",
    "        row_loc = [15,30,40,50,60,70,85]\n",
    "    else:\n",
    "        print(\"Reverse \" + str(i))\n",
    "        row_loc = [85, 70, 60, 50, 40, 30, 15]\n",
    "    return img_dict, row_loc, contrib, var_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9038eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_models(regen_top = False, regen = False, subfigs = None, models = None, datasets = None, group = None, full_set=True, entries = 500, fixed_patient = None, fixed_patient_values = None, label = [], race = False):\n",
    "    img_dict = {}\n",
    "    row_loc = {}\n",
    "    contrib = {}\n",
    "    var_ratio = {}\n",
    "    if not regen_top and os.path.isfile(PROJECT_DIR + \"/pub_pkl/\" + group + \"img_dict.pkl\"):\n",
    "        with open(PROJECT_DIR + \"/pub_pkl/\" + group + \"img_dict.pkl\", 'rb') as f:\n",
    "            img_dict = pickle.load(f)\n",
    "        with open(PROJECT_DIR + \"/pub_pkl/\" + group + \"row_loc.pkl\", 'rb') as f:\n",
    "            row_loc = pickle.load(f)\n",
    "        with open(PROJECT_DIR + \"/pub_pkl/\" + group + \"contrib.pkl\", 'rb') as f:\n",
    "            contrib = pickle.load(f)\n",
    "        with open(PROJECT_DIR + \"/pub_pkl/\" + group + \"var_ratio.pkl\", 'rb') as f:\n",
    "            var_ratio = pickle.load(f)\n",
    "    else:\n",
    "        if fixed_patient_values:\n",
    "            img_dict[datasets[0]], row_loc[datasets[0]], contrib[datasets[0]], var_ratio[datasets[0]] = load_models_site(models[0], dataset = datasets[0], entries = entries, full_set = full_set, regen = regen, fixed_patient = fixed_patient, fixed_patient_values = fixed_patient_values[0])\n",
    "            img_dict[datasets[1]], row_loc[datasets[1]], contrib[datasets[1]], var_ratio[datasets[1]] = load_models_site(models[1], dataset = datasets[1], entries = entries, full_set = full_set, regen = regen, fixed_patient = fixed_patient, fixed_patient_values = fixed_patient_values[1])\n",
    "            img_dict[datasets[2]], row_loc[datasets[2]], contrib[datasets[2]], var_ratio[datasets[2]] = load_models_site(models[2], dataset = datasets[2], entries = entries, full_set = full_set, regen = regen, fixed_patient = fixed_patient, fixed_patient_values = fixed_patient_values[2])\n",
    "            img_dict[datasets[3]], row_loc[datasets[3]], contrib[datasets[3]], var_ratio[datasets[3]] = load_models_site(models[3], dataset = datasets[3], entries = entries, full_set = full_set, regen = regen, fixed_patient = fixed_patient, fixed_patient_values = fixed_patient_values[3])        \n",
    "        else:\n",
    "            img_dict[datasets[0]], row_loc[datasets[0]], contrib[datasets[0]], var_ratio[datasets[0]] = load_models_site(models[0], dataset = datasets[0], entries = entries, full_set = full_set, regen = regen, fixed_patient = fixed_patient)\n",
    "            img_dict[datasets[1]], row_loc[datasets[1]], contrib[datasets[1]], var_ratio[datasets[1]] = load_models_site(models[1], dataset = datasets[1], entries = entries, full_set = full_set, regen = regen, fixed_patient = fixed_patient)\n",
    "            img_dict[datasets[2]], row_loc[datasets[2]], contrib[datasets[2]], var_ratio[datasets[2]] = load_models_site(models[2], dataset = datasets[2], entries = entries, full_set = full_set, regen = regen, fixed_patient = fixed_patient)\n",
    "            img_dict[datasets[3]], row_loc[datasets[3]], contrib[datasets[3]], var_ratio[datasets[3]] = load_models_site(models[3], dataset = datasets[3], entries = entries, full_set = full_set, regen = regen, fixed_patient = fixed_patient)\n",
    "        with open(PROJECT_DIR + \"/pub_pkl/\" + group + \"img_dict.pkl\", 'wb') as f:\n",
    "            pickle.dump(img_dict, f)\n",
    "        with open(PROJECT_DIR + \"/pub_pkl/\" + group + \"row_loc.pkl\", 'wb') as f:\n",
    "            pickle.dump(row_loc, f)\n",
    "        with open(PROJECT_DIR + \"/pub_pkl/\" + group + \"contrib.pkl\", 'wb') as f:\n",
    "            pickle.dump(contrib, f)\n",
    "        with open(PROJECT_DIR + \"/pub_pkl/\" + group + \"var_ratio.pkl\", 'wb') as f:\n",
    "            pickle.dump(var_ratio, f)    \n",
    "    img_include = 3\n",
    "    rows = len(img_dict)\n",
    "    #gs = plt.GridSpec(ncols = img_include, nrows = rows, left = 0, top = 1, right = 1, bottom = 0, wspace=0, hspace=0)\n",
    "    #gs_final = plt.GridSpec(ncols = img_include, nrows = rows, left = 0, top = 1, right = 1, bottom = 0, wspace=0, hspace=0)\n",
    "    #, axes = plt.subplots(rows, img_include, figsize = (2*img_include,2*rows))\n",
    "    axs = subfigs[0].subplots(len(img_dict), img_include)\n",
    "    \n",
    "    col = 0\n",
    "    axs2 = subfigs[1].subplots(len(img_dict), 1)\n",
    "    \n",
    "    for img_name in img_dict:\n",
    "        row_loc[img_name] = [row_loc[img_name][1], row_loc[img_name][3], row_loc[img_name][5]]\n",
    "        row = 0\n",
    "        for row_item in row_loc[img_name]:   \n",
    "            axs[col][row].imshow(img_dict[img_name][row_item])\n",
    "            #axs[col][row].spines['right'].set_visible(False)\n",
    "            #axs[col][row].spines['top'].set_visible(False)\n",
    "            #axs[col][row].spines['left'].set_visible(False)\n",
    "            #axs[col][row].spines['bottom'].set_visible(False)\n",
    "            axs[col][row].set_xticks([])\n",
    "            axs[col][row].set_yticks([])\n",
    "            axs[col][row].xaxis.set_label_position('top')\n",
    "            row = row + 1\n",
    "        axs[col][0].set_ylabel(img_name, size = 18)\n",
    "\n",
    "        axs2[col].barh([1 - 0.2], [contrib[img_name]], height = 0.8, label = \"Contribution to Prediction\")\n",
    "        axs2[col].barh([0 - 0.2], [var_ratio[img_name]], height = 0.8, label = \"Variance Explained\")\n",
    "\n",
    "        axs2[col].spines['right'].set_visible(False)\n",
    "        axs2[col].spines['top'].set_visible(False)\n",
    "        #axs[col][row].spines['left'].set_visible(False)\n",
    "        axs2[col].set_yticks([])\n",
    "        axs2[col].axes.get_yaxis().set_visible(False)\n",
    "        axs2[col].set_ylim([-1,2])\n",
    "        axs2[col].set_xlim([0,1])\n",
    "        #axs2[col].set_xlim([0, np.mean([result[x][important_pca[0]] for x in range(entries)]) / imp_total])\n",
    "        if col != rows - 1:\n",
    "            axs2[col].axes.get_xaxis().set_visible(False)\n",
    "            axs2[col].spines['bottom'].set_visible(False)\n",
    "        if col == 0:\n",
    "            axs2[col].legend(bbox_to_anchor=(0.04, 0.72))\n",
    "        col = col + 1\n",
    "    #plt.tight_layout()\n",
    "    subfigs[0].subplots_adjust(left = 0, top = 1, right = 1, bottom = 0 + 1/9, wspace=0, hspace=0)\n",
    "    subfigs[1].subplots_adjust(left = 0, top = 1, right = 1  - 4/16, bottom = 0  + 1/9, wspace=0, hspace=0)\n",
    "    axs[0][0].annotate(text=\"\", xy=(0.98, 1.032), xytext=(0.505,1.032), xycoords=\"subfigure fraction\",  arrowprops=dict(facecolor='C1'))\n",
    "    axs[0][0].annotate(text=\"\", xy=(0.02, 1.032), xytext=(0.495,1.032), xycoords=\"subfigure fraction\",  arrowprops=dict(facecolor='C0'))\n",
    "    axs[0][0].annotate(text=label[0], xy = (0.50,1.05), xycoords=\"subfigure fraction\", ha=\"center\", size = 18)\n",
    "    axs[0][0].annotate(text=label[1], xy = (0.10, 1.05), xycoords=\"subfigure fraction\", ha=\"center\", size = 16)\n",
    "    axs[0][0].annotate(text=label[2], xy = (0.90, 1.05), xycoords=\"subfigure fraction\", ha=\"center\", size = 16)\n",
    "\n",
    "    if race:\n",
    "        t = axs[0][0].annotate(text=\"Asian\", xy = (0.028, 1- 0.029), xycoords=\"axes fraction\", ha=\"left\", va=\"top\", size = 16)\n",
    "        t.set_bbox(dict(facecolor='white', alpha=1, edgecolor='black'))\n",
    "        t = axs[1][0].annotate(text=\"Asian\", xy = (0.028, 1- 0.029), xycoords=\"axes fraction\", ha=\"left\", va=\"top\", size = 16)\n",
    "        t.set_bbox(dict(facecolor='white', alpha=1, edgecolor='black'))\n",
    "        t = axs[2][0].annotate(text=\"African\", xy = (0.028, 1- 0.029), xycoords=\"axes fraction\", ha=\"left\", va=\"top\", size = 16)\n",
    "        t.set_bbox(dict(facecolor='white', alpha=1, edgecolor='black'))\n",
    "        t = axs[3][0].annotate(text=\"Asian\", xy = (0.028, 1- 0.029), xycoords=\"axes fraction\", ha=\"left\", va=\"top\", size = 16)\n",
    "        t.set_bbox(dict(facecolor='white', alpha=1, edgecolor='black'))\n",
    "\n",
    "        t = axs[0][row - 1].annotate(text=\"European\", xy = (1- 0.028, 1- 0.029), xycoords=\"axes fraction\", ha=\"right\", va=\"top\", size = 16)\n",
    "        t.set_bbox(dict(facecolor='white', alpha=1, edgecolor='black'))\n",
    "        t = axs[1][row - 1].annotate(text=\"European\", xy = (1- 0.028, 1- 0.029), xycoords=\"axes fraction\", ha=\"right\", va=\"top\", size = 16)\n",
    "        t.set_bbox(dict(facecolor='white', alpha=1, edgecolor='black'))\n",
    "        t = axs[2][row - 1].annotate(text=\"European\", xy = (1- 0.028, 1- 0.029), xycoords=\"axes fraction\", ha=\"right\", va=\"top\", size = 16)\n",
    "        t.set_bbox(dict(facecolor='white', alpha=1, edgecolor='black'))\n",
    "        t = axs[3][row - 1].annotate(text=\"European\", xy = (1- 0.028, 1- 0.029), xycoords=\"axes fraction\", ha=\"right\", va=\"top\", size = 16)\n",
    "        t.set_bbox(dict(facecolor='white', alpha=1, edgecolor='black'))\n",
    "    \n",
    "    subfigs[0].text(-0.05,1.02, label[3], zorder = 30, clip_on = False, weight='bold', size = 20 )\n",
    "    subfigs[1].text(-0.01,1.02, label[4], zorder = 30, clip_on = False, weight='bold', size = 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3207a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_overall = plt.figure(figsize=(18, 18), dpi = 300)\n",
    "subfigs_overall = fig_overall.subfigures(2, 2)\n",
    "\n",
    "subfigs1 = subfigs_overall[0][0].subfigures(1, 2, width_ratios = [6, 3])\n",
    "plot_models(False, False, subfigs1, full_set = False, models = [PROJECT_DIR + \"/PRETRAINED_MODELS/BRCA_SITE/SITE-HP0_epoch3.zip\",\n",
    "                                                                PROJECT_DIR + \"/PRETRAINED_MODELS/BLCA_SITE/SITE-HP0_epoch3.zip\",\n",
    "                                                                PROJECT_DIR + \"/PRETRAINED_MODELS/COADREAD_SITE/SITE-HP0_epoch3.zip\",\n",
    "                                                                PROJECT_DIR + \"/PRETRAINED_MODELS/ESCA_SITE/SITE-HP0_epoch3.zip\"],\n",
    "                                                              datasets = ['BRCA', 'BLCA', 'COADREAD', 'ESCA'], group = 'A', fixed_patient = True, label = ['Site', 'Site 1', 'Site 2', 'A', ''])#, fixed_patient_values = [126, 453, 397, 138 ]) #fixed_patient = [True, True, True, True]) #'# \n",
    "                                                                #good: brca 119 (small area of cancer), 388 (too dark?), 136 (lots of lymph)\n",
    "                                                                #good: brca 124 - somewhat dark - COADREAD 392 - a little whiteish but good\n",
    "subfigs2 = subfigs_overall[1][1].subfigures(1, 2, width_ratios = [6, 3])\n",
    "plot_models(False, False, subfigs2, full_set = False, models = [PROJECT_DIR + \"/PRETRAINED_MODELS/BRCA_SITE_CYCLEGAN/SITE-HP0_epoch3.zip\",\n",
    "                                                                PROJECT_DIR + \"/PRETRAINED_MODELS/BLCA_SITE_CYCLEGAN/SITE-HP0_epoch3.zip\",\n",
    "                                                                PROJECT_DIR + \"/PRETRAINED_MODELS/COADREAD_SITE_CYCLEGAN/SITE-HP0_epoch3.zip\",\n",
    "                                                                PROJECT_DIR + \"/PRETRAINED_MODELS/ESCA_SITE_CYCLEGAN/SITE-HP0_epoch3.zip\"],\n",
    "                                                              datasets = ['BRCA', 'BLCA', 'COADREAD', 'ESCA'], group = 'C', fixed_patient = True, label = ['Site (CycleGAN Norm)', 'Site 1', 'Site 2', 'D', ''])\n",
    "\n",
    "subfigs3 = subfigs_overall[0][1].subfigures(1, 2, width_ratios = [6, 3])\n",
    "plot_models(False, False, subfigs3, full_set = False, models = [PROJECT_DIR + \"/PRETRAINED_MODELS/BRCA_SITE_REINHARD/SITE-HP0_epoch3.zip\",\n",
    "                                                                PROJECT_DIR + \"/PRETRAINED_MODELS/BLCA_SITE_REINHARD/SITE-HP0_epoch3.zip\",\n",
    "                                                                PROJECT_DIR + \"/PRETRAINED_MODELS/COADREAD_SITE_REINHARD/SITE-HP0_epoch3.zip\",\n",
    "                                                                PROJECT_DIR + \"/PRETRAINED_MODELS/ESCA_SITE_REINHARD/SITE-HP0_epoch3.zip\"],\n",
    "                                                              datasets = ['BRCA', 'BLCA', 'COADREAD', 'ESCA'], group = 'D', fixed_patient = True, label = ['Site (Reinhard Norm)', 'Site 1', 'Site 2', 'C', ''])\n",
    "\n",
    "subfigs4 = subfigs_overall[1][0].subfigures(1, 2, width_ratios = [6, 3])\n",
    "plot_models(False, False, subfigs4, full_set = False, models = [PROJECT_DIR + \"/PRETRAINED_MODELS/BRCA_ANCESTRY/SITE-HP0_epoch3.zip\",\n",
    "                                                                PROJECT_DIR + \"/PRETRAINED_MODELS/BLCA_ANCESTRY/SITE-HP0_epoch3.zip\",\n",
    "                                                                PROJECT_DIR + \"/PRETRAINED_MODELS/COADREAD_ANCESTRY/SITE-HP0_epoch3.zip\",\n",
    "                                                                PROJECT_DIR + \"/PRETRAINED_MODELS/ESCA_ANCESTRY/SITE-HP0_epoch3.zip\"],\n",
    "                                                              datasets = ['BRCA', 'BLCA', 'COADREAD', 'ESCA'], group = 'B', fixed_patient = True, label = ['Ancestry', '', '', 'B', ''], race = True) #, fixed_patient_values = [308, 495, 30, 335])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35769fce",
   "metadata": {},
   "source": [
    "# Explainability of PIK3CA and HRD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5126ad7",
   "metadata": {},
   "source": [
    "### Here, gradient descent is used to generate images that are more / less likely to be predicted to be PIK3CA mutated / HRD high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea43281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slideflow.model.torch import load as load_torch_model\n",
    "df_mod = pd.read_csv(PROJECT_DIR + '/PROJECTS/HistoXGAN/SAVED_FEATURES/brca_features_plot.csv')\n",
    "feat_cols = list(df_mod.columns.values)\n",
    "feat_cols = [f for f in feat_cols if 'Feature_' in f]\n",
    "base_num = 200\n",
    "from slideflow.gan.stylegan3.stylegan3 import dnnlib, legacy, utils\n",
    "with dnnlib.util.open_url(PROJECT_DIR + '/FINAL_MODELS/CTransPath/snapshot.pkl') as f:\n",
    "    G = legacy.load_network_pkl(f)['G_ema'].to(device)\n",
    "\n",
    "def get_img_dict(df_mod, m, base_imgs, regen = True):\n",
    "    if not regen and os.path.isfile(os.path.dirname(m) + \"img_dict.pkl\"):\n",
    "        with open(os.path.dirname(m) + \"img_dict.pkl\", 'rb') as f:\n",
    "            img_dict = pickle.load(f)\n",
    "            return img_dict\n",
    "        \n",
    "    img_dict = {}\n",
    "\n",
    "    model = load_torch_model(m).eval().to(device)\n",
    "    preprocess = sf.util.get_preprocess_fn(m)\n",
    "    \n",
    "    for b in base_imgs:\n",
    "        vector_base = torch.tensor([df_mod[feat_cols].loc[b, :].values.tolist()]).to(device)\n",
    "        vector_base.requires_grad = True\n",
    "        lr = 1e-3\n",
    "\n",
    "        optimizer = torch.optim.Adam([vector_base], lr=lr)\n",
    "        loss_fn = torch.nn.L1Loss().to(device)\n",
    "        softmax = torch.nn.Softmax()\n",
    "        imgs = []\n",
    "        for i in range(200):\n",
    "            optimizer.zero_grad()\n",
    "            img_gen = G(vector_base, 0, noise_mode ='const')#((G(vector_base, 0, noise_mode ='const') + 1)*127.5).clamp(0, 255).to(torch.uint8)\n",
    "            pred = softmax(model(img_gen))\n",
    "            loss = loss_fn(pred[0][1], torch.tensor(0).to(device))\n",
    "            if i in [0, 20, 50, 199]:        \n",
    "                imgs += [((img_gen + 1)*127.5).permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()]     \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        imgs = list(reversed(imgs))\n",
    "\n",
    "        vector_base = torch.tensor([df_mod[feat_cols].loc[b, :].values.tolist()]).to(device)\n",
    "        vector_base.requires_grad = True\n",
    "        optimizer = torch.optim.Adam([vector_base], lr=lr)\n",
    "\n",
    "\n",
    "        for i in range(200):\n",
    "            optimizer.zero_grad()\n",
    "            img_gen = G(vector_base, 0, noise_mode ='const')#((G(vector_base, 0, noise_mode ='const') + 1)*127.5).clamp(0, 255).to(torch.uint8)\n",
    "            if i in [20, 50, 199]:\n",
    "                imgs += [((img_gen + 1)*127.5).permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()]\n",
    "            pred = softmax(model(img_gen))\n",
    "            loss = loss_fn(pred[0][1], torch.tensor(1).to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        img_dict[b] = imgs\n",
    "    with open(os.path.dirname(m) + \"img_dict.pkl\", 'wb') as f:\n",
    "        pickle.dump(img_dict, f)\n",
    "    return img_dict\n",
    "\n",
    "\n",
    "def plot_model(df_mod, m, regen, subfig, label):\n",
    "    base_imgs =  [0, 1, 2, 3] #[100, 200, 401, 501]#[100, 200, 300, 400, 500, 600, 700, 800]\n",
    "    rows = len(base_imgs)\n",
    "    img_dict = get_img_dict(df_mod, m, base_imgs, regen = regen)\n",
    "    axs = subfig.subplots(rows, 7)\n",
    "    col = 0\n",
    "    for img_name in img_dict:\n",
    "        for row in range(len(img_dict[img_name])):   \n",
    "            axs[col][row].imshow(img_dict[img_name][row])\n",
    "            #axs[col][row].spines['right'].set_visible(False)\n",
    "            #axs[col][row].spines['top'].set_visible(False)\n",
    "            #axs[col][row].spines['left'].set_visible(False)\n",
    "            #axs[col][row].spines['bottom'].set_visible(False)\n",
    "            axs[col][row].set_xticks([])\n",
    "            axs[col][row].set_yticks([])\n",
    "            axs[col][row].xaxis.set_label_position('top')\n",
    "        #axs[col][0].set_ylabel(img_name, size = 18)\n",
    "        col = col + 1\n",
    "    count = 0\n",
    "    \n",
    "    subfig.subplots_adjust(left = 0, top = 1, right = 1, bottom = 0 + 2/18, wspace=0, hspace=0)\n",
    "    axs[0][0].annotate(text=\"\", xy=(0.98, 1.032), xytext=(0.505,1.032), xycoords=\"subfigure fraction\",  arrowprops=dict(facecolor='C1'))\n",
    "    axs[0][0].annotate(text=\"\", xy=(0.02, 1.032), xytext=(0.495,1.032), xycoords=\"subfigure fraction\",  arrowprops=dict(facecolor='C0'))\n",
    "    axs[0][0].annotate(text=label[0], xy = (0.50,1.05), xycoords=\"subfigure fraction\", ha=\"center\", size = 18)\n",
    "    axs[0][0].annotate(text=label[1], xy = (0.02, 1.05), xycoords=\"subfigure fraction\", ha=\"center\", size = 16)\n",
    "    axs[0][0].annotate(text=label[2], xy = (0.98, 1.05), xycoords=\"subfigure fraction\", ha=\"center\", size = 16)\n",
    "\n",
    "    subfig.text(-0.03,1.02,label[3], zorder = 30, clip_on = False, weight='bold', size = 20 )\n",
    "\n",
    "    \n",
    "fig_overall = plt.figure(figsize=(14, 18), dpi = 300)\n",
    "subfig = fig_overall.subfigures(2, 1)\n",
    "plt.tight_layout()\n",
    "plot_model(df_mod, PROJECT_DIR + \"/PRETRAINED_MODELS/PIK3CA/PIK3CA-HP0.zip\", regen = False, subfig = subfig[0], label = [\"PIK3CA\", \"WT\", \"MUT\", \"A\"] )\n",
    "plot_model(df_mod, PROJECT_DIR + \"/PRETRAINED_MODELS/HRD/HRD-HP0.zip\", regen = False, subfig = subfig[1], label = [\"HRD\", \"Low\", \"High\", \"B\"])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b42f26",
   "metadata": {},
   "source": [
    "## The following was used to generate videos for pathologists to review for PIK3CA / HRD transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f7424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slideflow.model.torch import load as load_torch_model\n",
    "import torch\n",
    "import slideflow as sf\n",
    "device = torch.device('cuda:3')\n",
    "\n",
    "feat_cols = list(df_mod.columns.values)\n",
    "feat_cols = [f for f in feat_cols if 'Feature_' in f]\n",
    "from slideflow.gan.stylegan3.stylegan3 import dnnlib, legacy, utils\n",
    "with dnnlib.util.open_url(PROJECT_DIR + '/FINAL_MODELS/CTransPath/snapshot.pkl') as f:\n",
    "    G = legacy.load_network_pkl(f)['G_ema'].to(device)\n",
    "    \n",
    "    \n",
    "def get_img_dict_full(df_mod, m, base_img, regen = True):\n",
    "    model = load_torch_model(m).eval().to(device)\n",
    "    preprocess = sf.util.get_preprocess_fn(m)   \n",
    "\n",
    "    \n",
    "    vector_base = torch.tensor([df_mod[feat_cols].loc[base_img, :].values.tolist()]).to(device)\n",
    "    vector_base.requires_grad = True\n",
    "    lr = 5e-4\n",
    "\n",
    "    optimizer = torch.optim.Adam([vector_base], lr=lr)\n",
    "    loss_fn = torch.nn.L1Loss().to(device)\n",
    "    softmax = torch.nn.Softmax()\n",
    "    imgs = []\n",
    "    for i in range(50):\n",
    "        optimizer.zero_grad()\n",
    "        img_gen = G(vector_base, 0, noise_mode ='const')#((G(vector_base, 0, noise_mode ='const') + 1)*127.5).clamp(0, 255).to(torch.uint8)\n",
    "        pred = softmax(model(img_gen))\n",
    "        loss = loss_fn(pred[0][1], torch.tensor(0).to(device))\n",
    "        imgs += [((img_gen + 1)*127.5).permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()]     \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    imgs = list(reversed(imgs))\n",
    "\n",
    "    vector_base = torch.tensor([df_mod[feat_cols].loc[base_img, :].values.tolist()]).to(device)\n",
    "    vector_base.requires_grad = True\n",
    "    optimizer = torch.optim.Adam([vector_base], lr=lr)\n",
    "\n",
    "\n",
    "    for i in range(50):\n",
    "        optimizer.zero_grad()\n",
    "        img_gen = G(vector_base, 0, noise_mode ='const')#((G(vector_base, 0, noise_mode ='const') + 1)*127.5).clamp(0, 255).to(torch.uint8)\n",
    "        imgs += [((img_gen + 1)*127.5).permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()]\n",
    "        pred = softmax(model(img_gen))\n",
    "        loss = loss_fn(pred[0][1], torch.tensor(1).to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return imgs\n",
    "\n",
    "def save_vectors_pathologist(df_mod, m):\n",
    "    from slideflow.gan.stylegan3.stylegan3 import dnnlib, legacy, utils\n",
    "    from random import randrange\n",
    "    n_entries = len(df_mod.index)\n",
    "    for i in range(50):\n",
    "        r = randrange(n_entries)\n",
    "        video_path = os.path.dirname(m) + \"/\" + str(r) + '__pik3ca_video.mp4'\n",
    "        utils.save_video(get_img_dict_full(df_mod, m, r), path=video_path)        \n",
    "\n",
    "df_mod = pd.read_csv(PROJECT_DIR + '/PROJECTS/HistoXGAN/SAVED_FEATURES/brca_features_part.csv')\n",
    "save_vectors_pathologist(df_mod, PROJECT_DIR + \"/PRETRAINED_MODELS/PIK3CA/PIK3CA-HP0_epoch3.zip\")\n",
    "save_vectors_pathologist(df_mod, PROJECT_DIR + \"/PRETRAINED_MODELS/HRD/HRD-HP0_epoch3.zip\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
